{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision is installed in: /home/hoon2/anaconda3/envs/pda/lib/python3.9/site-packages/torchvision\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import os\n",
    "\n",
    "torchvision_dir = os.path.dirname(torchvision.__file__)\n",
    "print(\"torchvision is installed in:\", torchvision_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swint_s output shape: torch.Size([1, 400])\n",
      "swint_b output shape: torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.video import swin3d_s, swin3d_b\n",
    "\n",
    "model = swin3d_s(weights=None)\n",
    "model2 = swin3d_b(weights=None)\n",
    "\n",
    "dummy_input = torch.randn(1, 30, 3, 256, 256)\n",
    "dummy_input = dummy_input.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "output_s = model(dummy_input)\n",
    "output_b = model2(dummy_input)\n",
    "\n",
    "print(\"swint_s output shape:\", output_s.shape)\n",
    "print(\"swint_b output shape:\", output_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=400, bias=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "in_features = model.head.in_features  \n",
    "model.head = nn.Linear(in_features, 4)\n",
    "\n",
    "in_features = model2.head.in_features \n",
    "model2.head = nn.Linear(in_features, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=4, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                       | #elements or shape   |\n",
      "|:---------------------------|:---------------------|\n",
      "| model                      | 49.5M                |\n",
      "|  patch_embed               |  9.5K                |\n",
      "|   patch_embed.proj         |   9.3K               |\n",
      "|    patch_embed.proj.weight |    (96, 3, 2, 4, 4)  |\n",
      "|    patch_embed.proj.bias   |    (96,)             |\n",
      "|   patch_embed.norm         |   0.2K               |\n",
      "|    patch_embed.norm.weight |    (96,)             |\n",
      "|    patch_embed.norm.bias   |    (96,)             |\n",
      "|  features                  |  49.5M               |\n",
      "|   features.0               |   0.2M               |\n",
      "|    features.0.0            |    0.1M              |\n",
      "|    features.0.1            |    0.1M              |\n",
      "|   features.1               |   74.5K              |\n",
      "|    features.1.reduction    |    73.7K             |\n",
      "|    features.1.norm         |    0.8K              |\n",
      "|   features.2               |   0.9M               |\n",
      "|    features.2.0            |    0.5M              |\n",
      "|    features.2.1            |    0.5M              |\n",
      "|   features.3               |   0.3M               |\n",
      "|    features.3.reduction    |    0.3M              |\n",
      "|    features.3.norm         |    1.5K              |\n",
      "|   features.4               |   32.5M              |\n",
      "|    features.4.0            |    1.8M              |\n",
      "|    features.4.1            |    1.8M              |\n",
      "|    features.4.2            |    1.8M              |\n",
      "|    features.4.3            |    1.8M              |\n",
      "|    features.4.4            |    1.8M              |\n",
      "|    features.4.5            |    1.8M              |\n",
      "|    features.4.6            |    1.8M              |\n",
      "|    features.4.7            |    1.8M              |\n",
      "|    features.4.8            |    1.8M              |\n",
      "|    features.4.9            |    1.8M              |\n",
      "|    features.4.10           |    1.8M              |\n",
      "|    features.4.11           |    1.8M              |\n",
      "|    features.4.12           |    1.8M              |\n",
      "|    features.4.13           |    1.8M              |\n",
      "|    features.4.14           |    1.8M              |\n",
      "|    features.4.15           |    1.8M              |\n",
      "|    features.4.16           |    1.8M              |\n",
      "|    features.4.17           |    1.8M              |\n",
      "|   features.5               |   1.2M               |\n",
      "|    features.5.reduction    |    1.2M              |\n",
      "|    features.5.norm         |    3.1K              |\n",
      "|   features.6               |   14.3M              |\n",
      "|    features.6.0            |    7.1M              |\n",
      "|    features.6.1            |    7.1M              |\n",
      "|  norm                      |  1.5K                |\n",
      "|   norm.weight              |   (768,)             |\n",
      "|   norm.bias                |   (768,)             |\n",
      "|  head                      |  3.1K                |\n",
      "|   head.weight              |   (4, 768)           |\n",
      "|   head.bias                |   (4,)               |\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "\n",
    "print(parameter_count_table(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                       | #elements or shape   |\n",
      "|:---------------------------|:---------------------|\n",
      "| model                      | 87.6M                |\n",
      "|  patch_embed               |  12.7K               |\n",
      "|   patch_embed.proj         |   12.4K              |\n",
      "|    patch_embed.proj.weight |    (128, 3, 2, 4, 4) |\n",
      "|    patch_embed.proj.bias   |    (128,)            |\n",
      "|   patch_embed.norm         |   0.3K               |\n",
      "|    patch_embed.norm.weight |    (128,)            |\n",
      "|    patch_embed.norm.bias   |    (128,)            |\n",
      "|  features                  |  87.6M               |\n",
      "|   features.0               |   0.4M               |\n",
      "|    features.0.0            |    0.2M              |\n",
      "|    features.0.1            |    0.2M              |\n",
      "|   features.1               |   0.1M               |\n",
      "|    features.1.reduction    |    0.1M              |\n",
      "|    features.1.norm         |    1.0K              |\n",
      "|   features.2               |   1.6M               |\n",
      "|    features.2.0            |    0.8M              |\n",
      "|    features.2.1            |    0.8M              |\n",
      "|   features.3               |   0.5M               |\n",
      "|    features.3.reduction    |    0.5M              |\n",
      "|    features.3.norm         |    2.0K              |\n",
      "|   features.4               |   57.5M              |\n",
      "|    features.4.0            |    3.2M              |\n",
      "|    features.4.1            |    3.2M              |\n",
      "|    features.4.2            |    3.2M              |\n",
      "|    features.4.3            |    3.2M              |\n",
      "|    features.4.4            |    3.2M              |\n",
      "|    features.4.5            |    3.2M              |\n",
      "|    features.4.6            |    3.2M              |\n",
      "|    features.4.7            |    3.2M              |\n",
      "|    features.4.8            |    3.2M              |\n",
      "|    features.4.9            |    3.2M              |\n",
      "|    features.4.10           |    3.2M              |\n",
      "|    features.4.11           |    3.2M              |\n",
      "|    features.4.12           |    3.2M              |\n",
      "|    features.4.13           |    3.2M              |\n",
      "|    features.4.14           |    3.2M              |\n",
      "|    features.4.15           |    3.2M              |\n",
      "|    features.4.16           |    3.2M              |\n",
      "|    features.4.17           |    3.2M              |\n",
      "|   features.5               |   2.1M               |\n",
      "|    features.5.reduction    |    2.1M              |\n",
      "|    features.5.norm         |    4.1K              |\n",
      "|   features.6               |   25.4M              |\n",
      "|    features.6.0            |    12.7M             |\n",
      "|    features.6.1            |    12.7M             |\n",
      "|  norm                      |  2.0K                |\n",
      "|   norm.weight              |   (1024,)            |\n",
      "|   norm.bias                |   (1024,)            |\n",
      "|  head                      |  4.1K                |\n",
      "|   head.weight              |   (4, 1024)          |\n",
      "|   head.bias                |   (4,)               |\n"
     ]
    }
   ],
   "source": [
    "print(parameter_count_table(model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mvit_v2_s output shape: torch.Size([1, 400])\n",
      "mvit_v2_b output shape: torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.video import mvit_v2_s, mvit_v1_b\n",
    "\n",
    "model = mvit_v2_s(weights=None)\n",
    "model2 = mvit_v1_b(weights=None)\n",
    "\n",
    "dummy_input = torch.randn(1, 30, 3, 256, 256)\n",
    "dummy_input = dummy_input.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "output_v2_s = model(dummy_input)\n",
    "output_v1_b = model2(dummy_input)\n",
    "\n",
    "print(\"mvit_v2_s output shape:\", output_v2_s.shape)\n",
    "print(\"mvit_v2_b output shape:\", output_v1_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "in_features = model.head[1].in_features  # 기존 in_features 유지\n",
    "model.head[1] = nn.Linear(in_features, 4)\n",
    "\n",
    "in_features = model2.head[1].in_features  # 기존 in_features 유지\n",
    "model2.head[1] = nn.Linear(in_features, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MViT(\n",
       "  (conv_proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))\n",
       "  (pos_encoding): PositionalEncoding()\n",
       "  (blocks): ModuleList(\n",
       "    (0): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=384, out_features=192, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      (project): Linear(in_features=96, out_features=192, bias=True)\n",
       "    )\n",
       "    (1): MultiscaleBlock(\n",
       "      (pool_skip): Pool(\n",
       "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.013333333333333334, mode=row)\n",
       "    )\n",
       "    (2): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.02666666666666667, mode=row)\n",
       "      (project): Linear(in_features=192, out_features=384, bias=True)\n",
       "    )\n",
       "    (3): MultiscaleBlock(\n",
       "      (pool_skip): Pool(\n",
       "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.04000000000000001, mode=row)\n",
       "    )\n",
       "    (4): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.05333333333333334, mode=row)\n",
       "    )\n",
       "    (5): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
       "    )\n",
       "    (6): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.08000000000000002, mode=row)\n",
       "    )\n",
       "    (7): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.09333333333333334, mode=row)\n",
       "    )\n",
       "    (8): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.10666666666666667, mode=row)\n",
       "    )\n",
       "    (9): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
       "    )\n",
       "    (10): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
       "    )\n",
       "    (11): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.14666666666666667, mode=row)\n",
       "    )\n",
       "    (12): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.16000000000000003, mode=row)\n",
       "    )\n",
       "    (13): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.17333333333333334, mode=row)\n",
       "      (project): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "    (14): MultiscaleBlock(\n",
       "      (pool_skip): Pool(\n",
       "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.18666666666666668, mode=row)\n",
       "    )\n",
       "    (15): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=True)\n",
       "    (1): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                       | #elements or shape   |\n",
      "|:---------------------------|:---------------------|\n",
      "| model                      | 34.3M                |\n",
      "|  conv_proj                 |  42.4K               |\n",
      "|   conv_proj.weight         |   (96, 3, 3, 7, 7)   |\n",
      "|   conv_proj.bias           |   (96,)              |\n",
      "|  pos_encoding              |  96                  |\n",
      "|   pos_encoding.class_token |   (96,)              |\n",
      "|  blocks                    |  34.2M               |\n",
      "|   blocks.0                 |   0.1M               |\n",
      "|    blocks.0.norm1          |    0.2K              |\n",
      "|    blocks.0.norm2          |    0.2K              |\n",
      "|    blocks.0.attn           |    72.8K             |\n",
      "|    blocks.0.mlp            |    74.2K             |\n",
      "|   blocks.1                 |   0.4M               |\n",
      "|    blocks.1.norm1          |    0.2K              |\n",
      "|    blocks.1.norm2          |    0.4K              |\n",
      "|    blocks.1.attn           |    0.1M              |\n",
      "|    blocks.1.mlp            |    0.3M              |\n",
      "|    blocks.1.project        |    18.6K             |\n",
      "|   blocks.2                 |   0.5M               |\n",
      "|    blocks.2.norm1          |    0.4K              |\n",
      "|    blocks.2.norm2          |    0.4K              |\n",
      "|    blocks.2.attn           |    0.2M              |\n",
      "|    blocks.2.mlp            |    0.3M              |\n",
      "|   blocks.3                 |   1.6M               |\n",
      "|    blocks.3.norm1          |    0.4K              |\n",
      "|    blocks.3.norm2          |    0.8K              |\n",
      "|    blocks.3.attn           |    0.4M              |\n",
      "|    blocks.3.mlp            |    1.2M              |\n",
      "|    blocks.3.project        |    74.1K             |\n",
      "|   blocks.4                 |   1.8M               |\n",
      "|    blocks.4.norm1          |    0.8K              |\n",
      "|    blocks.4.norm2          |    0.8K              |\n",
      "|    blocks.4.attn           |    0.6M              |\n",
      "|    blocks.4.mlp            |    1.2M              |\n",
      "|   blocks.5                 |   1.8M               |\n",
      "|    blocks.5.norm1          |    0.8K              |\n",
      "|    blocks.5.norm2          |    0.8K              |\n",
      "|    blocks.5.attn           |    0.6M              |\n",
      "|    blocks.5.mlp            |    1.2M              |\n",
      "|   blocks.6                 |   1.8M               |\n",
      "|    blocks.6.norm1          |    0.8K              |\n",
      "|    blocks.6.norm2          |    0.8K              |\n",
      "|    blocks.6.attn           |    0.6M              |\n",
      "|    blocks.6.mlp            |    1.2M              |\n",
      "|   blocks.7                 |   1.8M               |\n",
      "|    blocks.7.norm1          |    0.8K              |\n",
      "|    blocks.7.norm2          |    0.8K              |\n",
      "|    blocks.7.attn           |    0.6M              |\n",
      "|    blocks.7.mlp            |    1.2M              |\n",
      "|   blocks.8                 |   1.8M               |\n",
      "|    blocks.8.norm1          |    0.8K              |\n",
      "|    blocks.8.norm2          |    0.8K              |\n",
      "|    blocks.8.attn           |    0.6M              |\n",
      "|    blocks.8.mlp            |    1.2M              |\n",
      "|   blocks.9                 |   1.8M               |\n",
      "|    blocks.9.norm1          |    0.8K              |\n",
      "|    blocks.9.norm2          |    0.8K              |\n",
      "|    blocks.9.attn           |    0.6M              |\n",
      "|    blocks.9.mlp            |    1.2M              |\n",
      "|   blocks.10                |   1.8M               |\n",
      "|    blocks.10.norm1         |    0.8K              |\n",
      "|    blocks.10.norm2         |    0.8K              |\n",
      "|    blocks.10.attn          |    0.6M              |\n",
      "|    blocks.10.mlp           |    1.2M              |\n",
      "|   blocks.11                |   1.8M               |\n",
      "|    blocks.11.norm1         |    0.8K              |\n",
      "|    blocks.11.norm2         |    0.8K              |\n",
      "|    blocks.11.attn          |    0.6M              |\n",
      "|    blocks.11.mlp           |    1.2M              |\n",
      "|   blocks.12                |   1.8M               |\n",
      "|    blocks.12.norm1         |    0.8K              |\n",
      "|    blocks.12.norm2         |    0.8K              |\n",
      "|    blocks.12.attn          |    0.6M              |\n",
      "|    blocks.12.mlp           |    1.2M              |\n",
      "|   blocks.13                |   1.8M               |\n",
      "|    blocks.13.norm1         |    0.8K              |\n",
      "|    blocks.13.norm2         |    0.8K              |\n",
      "|    blocks.13.attn          |    0.6M              |\n",
      "|    blocks.13.mlp           |    1.2M              |\n",
      "|   blocks.14                |   6.5M               |\n",
      "|    blocks.14.norm1         |    0.8K              |\n",
      "|    blocks.14.norm2         |    1.5K              |\n",
      "|    blocks.14.attn          |    1.5M              |\n",
      "|    blocks.14.mlp           |    4.7M              |\n",
      "|    blocks.14.project       |    0.3M              |\n",
      "|   blocks.15                |   7.1M               |\n",
      "|    blocks.15.norm1         |    1.5K              |\n",
      "|    blocks.15.norm2         |    1.5K              |\n",
      "|    blocks.15.attn          |    2.4M              |\n",
      "|    blocks.15.mlp           |    4.7M              |\n",
      "|  norm                      |  1.5K                |\n",
      "|   norm.weight              |   (768,)             |\n",
      "|   norm.bias                |   (768,)             |\n",
      "|  head                      |  3.1K                |\n",
      "|   head.1                   |   3.1K               |\n",
      "|    head.1.weight           |    (4, 768)          |\n",
      "|    head.1.bias             |    (4,)              |\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "\n",
    "print(parameter_count_table(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                        | #elements or shape   |\n",
      "|:----------------------------|:---------------------|\n",
      "| model                       | 36.4M                |\n",
      "|  conv_proj                  |  42.4K               |\n",
      "|   conv_proj.weight          |   (96, 3, 3, 7, 7)   |\n",
      "|   conv_proj.bias            |   (96,)              |\n",
      "|  pos_encoding               |  0.4M                |\n",
      "|   pos_encoding.class_token  |   (96,)              |\n",
      "|   pos_encoding.spatial_pos  |   (4096, 96)         |\n",
      "|   pos_encoding.temporal_pos |   (15, 96)           |\n",
      "|   pos_encoding.class_pos    |   (96,)              |\n",
      "|  blocks                     |  36.0M               |\n",
      "|   blocks.0                  |   0.2M               |\n",
      "|    blocks.0.norm1           |    0.2K              |\n",
      "|    blocks.0.norm2           |    0.2K              |\n",
      "|    blocks.0.attn            |    42.8K             |\n",
      "|    blocks.0.mlp             |    0.1M              |\n",
      "|    blocks.0.project         |    18.6K             |\n",
      "|   blocks.1                  |   0.5M               |\n",
      "|    blocks.1.norm1           |    0.4K              |\n",
      "|    blocks.1.norm2           |    0.4K              |\n",
      "|    blocks.1.attn            |    0.2M              |\n",
      "|    blocks.1.mlp             |    0.3M              |\n",
      "|   blocks.2                  |   0.7M               |\n",
      "|    blocks.2.norm1           |    0.4K              |\n",
      "|    blocks.2.norm2           |    0.4K              |\n",
      "|    blocks.2.attn            |    0.2M              |\n",
      "|    blocks.2.mlp             |    0.4M              |\n",
      "|    blocks.2.project         |    74.1K             |\n",
      "|   blocks.3                  |   1.8M               |\n",
      "|    blocks.3.norm1           |    0.8K              |\n",
      "|    blocks.3.norm2           |    0.8K              |\n",
      "|    blocks.3.attn            |    0.6M              |\n",
      "|    blocks.3.mlp             |    1.2M              |\n",
      "|   blocks.4                  |   1.8M               |\n",
      "|    blocks.4.norm1           |    0.8K              |\n",
      "|    blocks.4.norm2           |    0.8K              |\n",
      "|    blocks.4.attn            |    0.6M              |\n",
      "|    blocks.4.mlp             |    1.2M              |\n",
      "|   blocks.5                  |   1.8M               |\n",
      "|    blocks.5.norm1           |    0.8K              |\n",
      "|    blocks.5.norm2           |    0.8K              |\n",
      "|    blocks.5.attn            |    0.6M              |\n",
      "|    blocks.5.mlp             |    1.2M              |\n",
      "|   blocks.6                  |   1.8M               |\n",
      "|    blocks.6.norm1           |    0.8K              |\n",
      "|    blocks.6.norm2           |    0.8K              |\n",
      "|    blocks.6.attn            |    0.6M              |\n",
      "|    blocks.6.mlp             |    1.2M              |\n",
      "|   blocks.7                  |   1.8M               |\n",
      "|    blocks.7.norm1           |    0.8K              |\n",
      "|    blocks.7.norm2           |    0.8K              |\n",
      "|    blocks.7.attn            |    0.6M              |\n",
      "|    blocks.7.mlp             |    1.2M              |\n",
      "|   blocks.8                  |   1.8M               |\n",
      "|    blocks.8.norm1           |    0.8K              |\n",
      "|    blocks.8.norm2           |    0.8K              |\n",
      "|    blocks.8.attn            |    0.6M              |\n",
      "|    blocks.8.mlp             |    1.2M              |\n",
      "|   blocks.9                  |   1.8M               |\n",
      "|    blocks.9.norm1           |    0.8K              |\n",
      "|    blocks.9.norm2           |    0.8K              |\n",
      "|    blocks.9.attn            |    0.6M              |\n",
      "|    blocks.9.mlp             |    1.2M              |\n",
      "|   blocks.10                 |   1.8M               |\n",
      "|    blocks.10.norm1          |    0.8K              |\n",
      "|    blocks.10.norm2          |    0.8K              |\n",
      "|    blocks.10.attn           |    0.6M              |\n",
      "|    blocks.10.mlp            |    1.2M              |\n",
      "|   blocks.11                 |   1.8M               |\n",
      "|    blocks.11.norm1          |    0.8K              |\n",
      "|    blocks.11.norm2          |    0.8K              |\n",
      "|    blocks.11.attn           |    0.6M              |\n",
      "|    blocks.11.mlp            |    1.2M              |\n",
      "|   blocks.12                 |   1.8M               |\n",
      "|    blocks.12.norm1          |    0.8K              |\n",
      "|    blocks.12.norm2          |    0.8K              |\n",
      "|    blocks.12.attn           |    0.6M              |\n",
      "|    blocks.12.mlp            |    1.2M              |\n",
      "|   blocks.13                 |   2.7M               |\n",
      "|    blocks.13.norm1          |    0.8K              |\n",
      "|    blocks.13.norm2          |    0.8K              |\n",
      "|    blocks.13.attn           |    0.6M              |\n",
      "|    blocks.13.mlp            |    1.8M              |\n",
      "|    blocks.13.project        |    0.3M              |\n",
      "|   blocks.14                 |   7.1M               |\n",
      "|    blocks.14.norm1          |    1.5K              |\n",
      "|    blocks.14.norm2          |    1.5K              |\n",
      "|    blocks.14.attn           |    2.4M              |\n",
      "|    blocks.14.mlp            |    4.7M              |\n",
      "|   blocks.15                 |   7.1M               |\n",
      "|    blocks.15.norm1          |    1.5K              |\n",
      "|    blocks.15.norm2          |    1.5K              |\n",
      "|    blocks.15.attn           |    2.4M              |\n",
      "|    blocks.15.mlp            |    4.7M              |\n",
      "|  norm                       |  1.5K                |\n",
      "|   norm.weight               |   (768,)             |\n",
      "|   norm.bias                 |   (768,)             |\n",
      "|  head                       |  3.1K                |\n",
      "|   head.1                    |   3.1K               |\n",
      "|    head.1.weight            |    (4, 768)          |\n",
      "|    head.1.bias              |    (4,)              |\n"
     ]
    }
   ],
   "source": [
    "print(parameter_count_table(model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 4.512M\n",
      "Shape of out : torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "from vivit import *\n",
    "\n",
    "img = torch.ones([1, 16, 3, 256, 256])  # 수정: 256x256 크기의 입력 이미지 생성\n",
    "\n",
    "model = ViViT(256, 16, 100, 16)  # 수정: image_size를 256으로 설정\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "parameters = sum([np.prod(p.size()) for p in parameters]) / 1_000_000\n",
    "print('Trainable Parameters: %.3fM' % parameters)\n",
    "\n",
    "out = model(img)\n",
    "\n",
    "print(\"Shape of out :\", out.shape)  # [B, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.512292)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
