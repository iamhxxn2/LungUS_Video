{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "TS_reader1_df = pd.read_excel(\"/data2/hoon2/LUS_Dataset/csv_files/Temporally_separated_sheet_labeler1.xlsx\", index_col=False)\n",
    "TS_reader2_df = pd.read_excel(\"/data2/hoon2/LUS_Dataset/csv_files/Temporally_separated_sheet_labeler2.xlsx\", index_col=False)\n",
    "\n",
    "print(len(TS_reader1_df))\n",
    "print(len(TS_reader2_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pleural effusion</th>\n",
       "      <th>Lung sliding</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>3</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71_127</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>4</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>5</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36_48</td>\n",
       "      <td>46_61</td>\n",
       "      <td>126_130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>6</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37_47</td>\n",
       "      <td>47_58</td>\n",
       "      <td>126_130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "0               1   44937986         2   20240712     video         NaN   \n",
       "1               1   44937986         3   20240712     video         NaN   \n",
       "2               1   44937986         4   20240712     video         NaN   \n",
       "3               1   44937986         5   20240712     video         NaN   \n",
       "4               1   44937986         6   20240712     video         NaN   \n",
       "\n",
       "  A-line B-line Confluent B-line Consolidation Pleural effusion  Lung sliding  \\\n",
       "0  1_152    NaN              NaN           NaN              NaN             1   \n",
       "1    NaN    NaN              NaN        71_127            1_152             1   \n",
       "2    NaN    NaN              NaN         1_152            1_152             1   \n",
       "3  36_48  46_61          126_130           NaN              NaN             0   \n",
       "4  37_47  47_58          126_130           NaN              NaN             0   \n",
       "\n",
       "  Lung Ultrasound Score  LUS score align  \n",
       "0                     0                1  \n",
       "1                  3_ce                1  \n",
       "2                  3_ce                1  \n",
       "3                     2                0  \n",
       "4                     2                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pleural effusion</th>\n",
       "      <th>Lung sliding</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>3</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87_115</td>\n",
       "      <td>96_112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>4</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59_89</td>\n",
       "      <td>59_89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>5</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47_60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>6</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92_99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "0               1   44937986         2   20240712     video         NaN   \n",
       "1               1   44937986         3   20240712     video         NaN   \n",
       "2               1   44937986         4   20240712     video         NaN   \n",
       "3               1   44937986         5   20240712     video         NaN   \n",
       "4               1   44937986         6   20240712     video         NaN   \n",
       "\n",
       "  A-line B-line Confluent B-line Consolidation Pleural effusion  Lung sliding  \\\n",
       "0  1_152    NaN              NaN           NaN              NaN           1.0   \n",
       "1    NaN    NaN              NaN        87_115           96_112           0.0   \n",
       "2    NaN    NaN              NaN         59_89            59_89           0.0   \n",
       "3    NaN  47_60              NaN           NaN              NaN           0.0   \n",
       "4    NaN  92_99              NaN           NaN              NaN           1.0   \n",
       "\n",
       "  Lung Ultrasound Score  LUS score align  \n",
       "0                     0                1  \n",
       "1                  3_ce                1  \n",
       "2                  3_ce                1  \n",
       "3                     1                0  \n",
       "4                     1                0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pleural effusion</th>\n",
       "      <th>Lung sliding</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>3</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>0</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>4</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>0</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>5</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>135_152</td>\n",
       "      <td>101_143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>6</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_48</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>7</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>36_104</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>9</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96_152</td>\n",
       "      <td>88_131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>10</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>52_80</td>\n",
       "      <td>27_90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>11</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "5                2   52426014         2   20240712     video         NaN   \n",
       "6                2   52426014         3   20240712     video         NaN   \n",
       "7                2   52426014         4   20240712     video         NaN   \n",
       "8                2   52426014         5   20240712     video         NaN   \n",
       "9                2   52426014         6   20240712     video         NaN   \n",
       "10               2   52426014         7   20240712     video         NaN   \n",
       "11               2   52426014         8   20240712     video         NaN   \n",
       "12               2   52426014         9   20240712     video         NaN   \n",
       "13               2   52426014        10   20240712     video         NaN   \n",
       "14               2   52426014        11   20240712     video         NaN   \n",
       "\n",
       "     A-line  B-line Confluent B-line Consolidation Pleural effusion  \\\n",
       "5   130_152   1_152          137_152       137_152              NaN   \n",
       "6       NaN     NaN              NaN         1_152            1_152   \n",
       "7       NaN     NaN              NaN         1_152            1_152   \n",
       "8     1_152   1_152          135_152       101_143              NaN   \n",
       "9     1_152   1_152             1_48         1_152              NaN   \n",
       "10    1_152   1_152           36_104         1_152              NaN   \n",
       "11     1_33   1_152           38_152       117_152              NaN   \n",
       "12   96_152  88_131              NaN        94_152              NaN   \n",
       "13    1_152   1_152            52_80         27_90              NaN   \n",
       "14    1_152   1_152          130_152         1_152              NaN   \n",
       "\n",
       "    Lung sliding Lung Ultrasound Score  LUS score align  \n",
       "5              0                   3_c                0  \n",
       "6              0                  3_ce                1  \n",
       "7              0                  3_ce                1  \n",
       "8              0                   3_c                0  \n",
       "9              0                   3_c                0  \n",
       "10             0                   3_c                0  \n",
       "11             0                   3_c                0  \n",
       "12             0                   3_c                0  \n",
       "13             0                   3_c                0  \n",
       "14             0                   3_c                0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_df[TS_reader1_df['PatientID'] == 52426014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_reader1_df['A-line'] = TS_reader1_df['A-line'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader1_df['A-line'] = TS_reader1_df['A-line'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader1_df['B-line'] = TS_reader1_df['B-line'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader1_df['B-line'] = TS_reader1_df['B-line'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader1_df['Confluent B-line'] = TS_reader1_df['Confluent B-line'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader1_df['Confluent B-line'] = TS_reader1_df['Confluent B-line'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader1_df['Consolidation'] = TS_reader1_df['Consolidation'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader1_df['Consolidation'] = TS_reader1_df['Consolidation'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader1_df['Pleural effusion'] = TS_reader1_df['Pleural effusion'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader1_df['Pleural effusion'] = TS_reader1_df['Pleural effusion'].replace('', pd.NA, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_reader2_df['A-line'] = TS_reader2_df['A-line'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader2_df['A-line'] = TS_reader2_df['A-line'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader2_df['B-line'] = TS_reader2_df['B-line'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader2_df['B-line'] = TS_reader2_df['B-line'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader2_df['Confluent B-line'] = TS_reader2_df['Confluent B-line'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader2_df['Confluent B-line'] = TS_reader2_df['Confluent B-line'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader2_df['Consolidation'] = TS_reader2_df['Consolidation'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader2_df['Consolidation'] = TS_reader2_df['Consolidation'].replace('', pd.NA, inplace=False)\n",
    "\n",
    "TS_reader2_df['Pleural effusion'] = TS_reader2_df['Pleural effusion'].map(lambda x: x if pd.isna(x) else x.strip())\n",
    "TS_reader2_df['Pleural effusion'] = TS_reader2_df['Pleural effusion'].replace('', pd.NA, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row(row):\n",
    "    root_path = \"/data2/hoon2/LUS_Dataset/processed_temporally_separated_dataset_dcm\"\n",
    "    patient_id = int(row['PatientID'])\n",
    "    data_idx = int(row['Data_idx'])\n",
    "#     data_idx = f\"{row['Data_idx']:05d}\"\n",
    "    return f\"{patient_id}_{data_idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pleural effusion</th>\n",
       "      <th>Lung sliding</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>3</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87_115</td>\n",
       "      <td>96_112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>4</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59_89</td>\n",
       "      <td>59_89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3_ce</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>5</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47_60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>6</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92_99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "0               1   44937986         2   20240712     video         NaN   \n",
       "1               1   44937986         3   20240712     video         NaN   \n",
       "2               1   44937986         4   20240712     video         NaN   \n",
       "3               1   44937986         5   20240712     video         NaN   \n",
       "4               1   44937986         6   20240712     video         NaN   \n",
       "\n",
       "  A-line B-line Confluent B-line Consolidation Pleural effusion  Lung sliding  \\\n",
       "0  1_152    NaN              NaN           NaN              NaN           1.0   \n",
       "1    NaN    NaN              NaN        87_115           96_112           0.0   \n",
       "2    NaN    NaN              NaN         59_89            59_89           0.0   \n",
       "3    NaN  47_60              NaN           NaN              NaN           0.0   \n",
       "4    NaN  92_99              NaN           NaN              NaN           1.0   \n",
       "\n",
       "  Lung Ultrasound Score  LUS score align    study_id  \n",
       "0                     0                1  44937986_2  \n",
       "1                  3_ce                1  44937986_3  \n",
       "2                  3_ce                1  44937986_4  \n",
       "3                     1                0  44937986_5  \n",
       "4                     1                0  44937986_6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_df['study_id'] = TS_reader1_df.apply(create_row, axis=1)\n",
    "TS_reader2_df['study_id'] = TS_reader2_df.apply(create_row, axis=1)\n",
    "\n",
    "TS_reader2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pleural effusion</th>\n",
       "      <th>Lung sliding</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "11               2   52426014         8   20240712     video         NaN   \n",
       "\n",
       "   A-line B-line Confluent B-line Consolidation Pleural effusion  \\\n",
       "11   1_33  1_152           38_152       117_152              NaN   \n",
       "\n",
       "    Lung sliding Lung Ultrasound Score  LUS score align    study_id  \n",
       "11             0                   3_c                0  52426014_8  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_df[TS_reader1_df['study_id'] == '52426014_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "all_png_paths = glob('/data2/hoon2/LUS_Dataset/temporally_separated_dcm_to_png/*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8508\n"
     ]
    }
   ],
   "source": [
    "print(len(all_png_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8508 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8508/8508 [00:00<00:00, 277770.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data2 = []\n",
    "\n",
    "# 이미지 case는 제외하기 위해\n",
    "pattern = re.compile(r'(\\d+_\\d+)_\\d+')\n",
    "\n",
    "for i in tqdm(range(len(all_png_paths))):\n",
    "    file_name = all_png_paths[i].split('/')[-1].split('.')[0]\n",
    "    study_id = pattern.match(file_name)\n",
    "    if study_id:\n",
    "        \n",
    "        p1 = study_id.group(1).split('_')[0]\n",
    "        p2 = int(study_id.group(1).split('_')[1])\n",
    "        revised_study_id = f\"{p1}_{p2}\"\n",
    "        \n",
    "        data2.append({\n",
    "            'FileName': file_name,\n",
    "            'study_id': revised_study_id\n",
    "        })\n",
    "\n",
    "png_df = pd.DataFrame(data2, columns=['FileName', 'study_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80306634_00004_31</td>\n",
       "      <td>80306634_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80306634_00007_93</td>\n",
       "      <td>80306634_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80306634_00007_46</td>\n",
       "      <td>80306634_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80306634_00007_72</td>\n",
       "      <td>80306634_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80306634_00006_150</td>\n",
       "      <td>80306634_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FileName    study_id\n",
       "0   80306634_00004_31  80306634_4\n",
       "1   80306634_00007_93  80306634_7\n",
       "2   80306634_00007_46  80306634_7\n",
       "3   80306634_00007_72  80306634_7\n",
       "4  80306634_00006_150  80306634_6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8508\n",
      "Tempollary_Separated 환자 수 : 11\n",
      "Tempollary_Separated 추가된 비디오 수 : 56\n",
      "Tempollary_Separated 추가된 이미지 수 : 8508\n"
     ]
    }
   ],
   "source": [
    "# 두 데이터프레임의 공통된 'study_id' 값 찾기\n",
    "common_study_ids = set(TS_reader1_df['study_id']).intersection(set(png_df['study_id']))\n",
    "\n",
    "# 공통된 'study_id'만 포함하도록 각 데이터프레임 필터링\n",
    "TS_reader1_df_filtered = TS_reader1_df[TS_reader1_df['study_id'].isin(common_study_ids)]\n",
    "TS_png_df_filtered = png_df[png_df['study_id'].isin(common_study_ids)]\n",
    "\n",
    "# 필터링된 데이터프레임 병합\n",
    "TS_reader1_df_filtered = pd.merge(TS_reader1_df_filtered, TS_png_df_filtered, on='study_id')\n",
    "print(len(TS_reader1_df_filtered))\n",
    "print(f\"Tempollary_Separated 환자 수 : {len(set(TS_reader1_df_filtered['PatientID']))}\")\n",
    "print(f\"Tempollary_Separated 추가된 비디오 수 : {len(set(TS_reader1_df_filtered['study_id']))}\")\n",
    "print(f\"Tempollary_Separated 추가된 이미지 수 : {len(set(TS_reader1_df_filtered['FileName']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8508\n",
      "Tempollary_Separated 환자 수 : 11\n",
      "Tempollary_Separated 추가된 비디오 수 : 56\n",
      "Tempollary_Separated 추가된 이미지 수 : 8508\n"
     ]
    }
   ],
   "source": [
    "# 두 데이터프레임의 공통된 'study_id' 값 찾기\n",
    "common_study_ids = set(TS_reader2_df['study_id']).intersection(set(png_df['study_id']))\n",
    "\n",
    "# 공통된 'study_id'만 포함하도록 각 데이터프레임 필터링\n",
    "TS_reader2_df_filtered = TS_reader2_df[TS_reader2_df['study_id'].isin(common_study_ids)]\n",
    "TS_png_df_filtered = png_df[png_df['study_id'].isin(common_study_ids)]\n",
    "\n",
    "# 필터링된 데이터프레임 병합\n",
    "TS_reader2_df_filtered = pd.merge(TS_reader2_df_filtered, TS_png_df_filtered, on='study_id')\n",
    "print(len(TS_reader2_df_filtered))\n",
    "print(f\"Tempollary_Separated 환자 수 : {len(set(TS_reader2_df_filtered['PatientID']))}\")\n",
    "print(f\"Tempollary_Separated 추가된 비디오 수 : {len(set(TS_reader2_df_filtered['study_id']))}\")\n",
    "print(f\"Tempollary_Separated 추가된 이미지 수 : {len(set(TS_reader2_df_filtered['FileName']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(start, end=None):\n",
    "    # If only one number is provided, return a list with that number.\n",
    "    if end is None:\n",
    "        return [int(start)]\n",
    "    # If start and end are provided, return a list with numbers from start to end, inclusive.\n",
    "    else:\n",
    "        return list(range(int(start), int(end) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lbl_range_dict(df, lbl_name):\n",
    "    lbl_dict = {}\n",
    "    for si, lbl in df[['study_id',lbl_name]].values:\n",
    "        lbl_range_ls = []\n",
    "        if pd.isna(lbl):\n",
    "            lbl_dict[si] = 0\n",
    "        else:\n",
    "            refined_lbl = lbl.strip()\n",
    "            refined_lbl_ls = refined_lbl.split(',')\n",
    "            for r_lbl in refined_lbl_ls:\n",
    "                lbl_range = re.split(r'[_-]', r_lbl)\n",
    "                lbl_range_ls.append(create_list(*lbl_range))   \n",
    "            lbl_dict[si] = lbl_range_ls  \n",
    "    return lbl_dict       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeler 1 \n",
    "al_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'A-line')\n",
    "bl_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'B-line')\n",
    "cb_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'Confluent B-line')\n",
    "c_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'Consolidation')\n",
    "pe_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'Pleural effusion')\n",
    "\n",
    "# labler 2\n",
    "al_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'A-line')\n",
    "bl_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'B-line')\n",
    "cb_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'Confluent B-line')\n",
    "c_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'Consolidation')\n",
    "pe_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'Pleural effusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label_in_range(filename, label_range_dict):\n",
    "    file_info = filename.split('_')\n",
    "    study_id = '_'.join([file_info[0], str(int(file_info[1]))])\n",
    "    frame_idx = int(file_info[-1])\n",
    "    lbl_range_ls = label_range_dict[study_id]\n",
    "    if lbl_range_ls == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for lbl_range in lbl_range_ls:\n",
    "            if frame_idx in lbl_range:\n",
    "                return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_study_id(filename):\n",
    "    file_info = filename.split('_')\n",
    "    study_id = '_'.join([file_info[0], str(int(file_info[1]))])\n",
    "    return study_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeler 1\n",
    "TS_reader1_df_filtered['A-line_lbl'] = TS_reader1_df_filtered.FileName.map(lambda x: check_label_in_range(x, al_lbl_dict1))\n",
    "TS_reader1_df_filtered['B-line_lbl'] = TS_reader1_df_filtered.FileName.map(lambda x: check_label_in_range(x, bl_lbl_dict1))\n",
    "TS_reader1_df_filtered['Confluent B-line_lbl'] = TS_reader1_df_filtered.FileName.map(lambda x: check_label_in_range(x, cb_lbl_dict1))\n",
    "TS_reader1_df_filtered['Consolidation_lbl'] = TS_reader1_df_filtered.FileName.map(lambda x: check_label_in_range(x, c_lbl_dict1))\n",
    "TS_reader1_df_filtered['Pleural effusion_lbl'] = TS_reader1_df_filtered.FileName.map(lambda x: check_label_in_range(x, pe_lbl_dict1))\n",
    "\n",
    "# labeler 2\n",
    "TS_reader2_df_filtered['A-line_lbl'] = TS_reader2_df_filtered.FileName.map(lambda x: check_label_in_range(x, al_lbl_dict2))\n",
    "TS_reader2_df_filtered['B-line_lbl'] = TS_reader2_df_filtered.FileName.map(lambda x: check_label_in_range(x, bl_lbl_dict2))\n",
    "TS_reader2_df_filtered['Confluent B-line_lbl'] = TS_reader2_df_filtered.FileName.map(lambda x: check_label_in_range(x, cb_lbl_dict2))\n",
    "TS_reader2_df_filtered['Consolidation_lbl'] = TS_reader2_df_filtered.FileName.map(lambda x: check_label_in_range(x, c_lbl_dict2))\n",
    "TS_reader2_df_filtered['Pleural effusion_lbl'] = TS_reader2_df_filtered.FileName.map(lambda x: check_label_in_range(x, pe_lbl_dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(row):\n",
    "    root_path = \"/data2/hoon2/LUS_Dataset/temporally_separated_dcm_to_png\"\n",
    "    patient_id = int(row['PatientID'])\n",
    "    File_name = row['FileName']\n",
    "    data_idx = row['FileName'].split('_')[1]\n",
    "    frame_num =  row['FileName'].split('_')[-1]\n",
    "    return f\"{root_path}/{patient_id}/{str(patient_id)}_{str(data_idx).zfill(5)}_{str(frame_num)}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/hoon2/LUS_Dataset/temporally_separated_dcm_to_png/44937986/44937986_00002_135.png\n"
     ]
    }
   ],
   "source": [
    "TS_reader1_df_filtered['img_path'] = TS_reader1_df_filtered.apply(create_path, axis=1)\n",
    "TS_reader2_df_filtered['img_path'] = TS_reader2_df_filtered.apply(create_path, axis=1)\n",
    "\n",
    "print(TS_reader1_df_filtered.iloc[0]['img_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>...</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "      <th>FileName</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_2</td>\n",
       "      <td>52426014_00002_106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_2</td>\n",
       "      <td>52426014_00002_7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_2</td>\n",
       "      <td>52426014_00002_16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_2</td>\n",
       "      <td>52426014_00002_68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>137_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_2</td>\n",
       "      <td>52426014_00002_93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>11</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_11</td>\n",
       "      <td>52426014_00011_127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>11</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_11</td>\n",
       "      <td>52426014_00011_100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>11</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_11</td>\n",
       "      <td>52426014_00011_19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>11</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_11</td>\n",
       "      <td>52426014_00011_46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>11</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>130_152</td>\n",
       "      <td>1_152</td>\n",
       "      <td>...</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_11</td>\n",
       "      <td>52426014_00011_147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1520 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "760                2   52426014         2   20240712     video         NaN   \n",
       "761                2   52426014         2   20240712     video         NaN   \n",
       "762                2   52426014         2   20240712     video         NaN   \n",
       "763                2   52426014         2   20240712     video         NaN   \n",
       "764                2   52426014         2   20240712     video         NaN   \n",
       "...              ...        ...       ...        ...       ...         ...   \n",
       "2275               2   52426014        11   20240712     video         NaN   \n",
       "2276               2   52426014        11   20240712     video         NaN   \n",
       "2277               2   52426014        11   20240712     video         NaN   \n",
       "2278               2   52426014        11   20240712     video         NaN   \n",
       "2279               2   52426014        11   20240712     video         NaN   \n",
       "\n",
       "       A-line B-line Confluent B-line Consolidation  ...  \\\n",
       "760   130_152  1_152          137_152       137_152  ...   \n",
       "761   130_152  1_152          137_152       137_152  ...   \n",
       "762   130_152  1_152          137_152       137_152  ...   \n",
       "763   130_152  1_152          137_152       137_152  ...   \n",
       "764   130_152  1_152          137_152       137_152  ...   \n",
       "...       ...    ...              ...           ...  ...   \n",
       "2275    1_152  1_152          130_152         1_152  ...   \n",
       "2276    1_152  1_152          130_152         1_152  ...   \n",
       "2277    1_152  1_152          130_152         1_152  ...   \n",
       "2278    1_152  1_152          130_152         1_152  ...   \n",
       "2279    1_152  1_152          130_152         1_152  ...   \n",
       "\n",
       "     Lung Ultrasound Score  LUS score align     study_id            FileName  \\\n",
       "760                    3_c                0   52426014_2  52426014_00002_106   \n",
       "761                    3_c                0   52426014_2    52426014_00002_7   \n",
       "762                    3_c                0   52426014_2   52426014_00002_16   \n",
       "763                    3_c                0   52426014_2   52426014_00002_68   \n",
       "764                    3_c                0   52426014_2   52426014_00002_93   \n",
       "...                    ...              ...          ...                 ...   \n",
       "2275                   3_c                0  52426014_11  52426014_00011_127   \n",
       "2276                   3_c                0  52426014_11  52426014_00011_100   \n",
       "2277                   3_c                0  52426014_11   52426014_00011_19   \n",
       "2278                   3_c                0  52426014_11   52426014_00011_46   \n",
       "2279                   3_c                0  52426014_11  52426014_00011_147   \n",
       "\n",
       "     A-line_lbl B-line_lbl  Confluent B-line_lbl  Consolidation_lbl  \\\n",
       "760           0          1                     0                  0   \n",
       "761           0          1                     0                  0   \n",
       "762           0          1                     0                  0   \n",
       "763           0          1                     0                  0   \n",
       "764           0          1                     0                  0   \n",
       "...         ...        ...                   ...                ...   \n",
       "2275          1          1                     0                  1   \n",
       "2276          1          1                     0                  1   \n",
       "2277          1          1                     0                  1   \n",
       "2278          1          1                     0                  1   \n",
       "2279          1          1                     1                  1   \n",
       "\n",
       "      Pleural effusion_lbl                                           img_path  \n",
       "760                      0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "761                      0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "762                      0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "763                      0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "764                      0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "...                    ...                                                ...  \n",
       "2275                     0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "2276                     0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "2277                     0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "2278                     0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "2279                     0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "\n",
       "[1520 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_df_filtered\n",
    "TS_reader1_df_filtered[TS_reader1_df_filtered['PatientID'] == 52426014]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_avi_path(row):\n",
    "    parts = row['FileName'].split('_')\n",
    "    return f\"/data2/hoon2/LUS_Dataset/processed_temporally_separated_dataset_avi/{parts[0]}/{parts[1]}.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>...</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "      <th>FileName</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "0               1   44937986         2   20240712     video         NaN   \n",
       "1               1   44937986         2   20240712     video         NaN   \n",
       "2               1   44937986         2   20240712     video         NaN   \n",
       "3               1   44937986         2   20240712     video         NaN   \n",
       "4               1   44937986         2   20240712     video         NaN   \n",
       "\n",
       "  A-line B-line Confluent B-line Consolidation  ... Lung Ultrasound Score  \\\n",
       "0  1_152    NaN              NaN           NaN  ...                     0   \n",
       "1  1_152    NaN              NaN           NaN  ...                     0   \n",
       "2  1_152    NaN              NaN           NaN  ...                     0   \n",
       "3  1_152    NaN              NaN           NaN  ...                     0   \n",
       "4  1_152    NaN              NaN           NaN  ...                     0   \n",
       "\n",
       "   LUS score align    study_id            FileName A-line_lbl B-line_lbl  \\\n",
       "0                1  44937986_2  44937986_00002_135          1          0   \n",
       "1                1  44937986_2   44937986_00002_72          1          0   \n",
       "2                1  44937986_2    44937986_00002_1          1          0   \n",
       "3                1  44937986_2  44937986_00002_146          1          0   \n",
       "4                1  44937986_2    44937986_00002_3          1          0   \n",
       "\n",
       "   Confluent B-line_lbl  Consolidation_lbl  Pleural effusion_lbl  \\\n",
       "0                     0                  0                     0   \n",
       "1                     0                  0                     0   \n",
       "2                     0                  0                     0   \n",
       "3                     0                  0                     0   \n",
       "4                     0                  0                     0   \n",
       "\n",
       "                                            img_path  \n",
       "0  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "1  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "2  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "3  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "4  /data2/hoon2/LUS_Dataset/temporally_separated_...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader2_df_filtered.head()\n",
    "TS_reader1_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_reader1_df_filtered['raw_avi_path'] = TS_reader1_df_filtered.apply(create_raw_avi_path, axis=1)\n",
    "TS_reader2_df_filtered['raw_avi_path'] = TS_reader2_df_filtered.apply(create_raw_avi_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>...</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "      <th>FileName</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_avi_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>3</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71_127</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_3</td>\n",
       "      <td>44937986_00003_84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>4</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_4</td>\n",
       "      <td>44937986_00004_19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>5</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36_48</td>\n",
       "      <td>46_61</td>\n",
       "      <td>126_130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_5</td>\n",
       "      <td>44937986_00005_88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>6</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37_47</td>\n",
       "      <td>47_58</td>\n",
       "      <td>126_130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_6</td>\n",
       "      <td>44937986_00006_33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "0                 1   44937986         2   20240712     video         NaN   \n",
       "152               1   44937986         3   20240712     video         NaN   \n",
       "304               1   44937986         4   20240712     video         NaN   \n",
       "456               1   44937986         5   20240712     video         NaN   \n",
       "608               1   44937986         6   20240712     video         NaN   \n",
       "\n",
       "    A-line B-line Confluent B-line Consolidation  ... LUS score align  \\\n",
       "0    1_152    NaN              NaN           NaN  ...               1   \n",
       "152    NaN    NaN              NaN        71_127  ...               1   \n",
       "304    NaN    NaN              NaN         1_152  ...               1   \n",
       "456  36_48  46_61          126_130           NaN  ...               0   \n",
       "608  37_47  47_58          126_130           NaN  ...               0   \n",
       "\n",
       "       study_id            FileName  A-line_lbl B-line_lbl  \\\n",
       "0    44937986_2  44937986_00002_135           1          0   \n",
       "152  44937986_3   44937986_00003_84           0          0   \n",
       "304  44937986_4   44937986_00004_19           0          0   \n",
       "456  44937986_5   44937986_00005_88           0          0   \n",
       "608  44937986_6   44937986_00006_33           0          0   \n",
       "\n",
       "    Confluent B-line_lbl  Consolidation_lbl  Pleural effusion_lbl  \\\n",
       "0                      0                  0                     0   \n",
       "152                    0                  1                     1   \n",
       "304                    0                  1                     1   \n",
       "456                    0                  0                     0   \n",
       "608                    0                  0                     0   \n",
       "\n",
       "                                              img_path  \\\n",
       "0    /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "152  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "304  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "456  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "608  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "\n",
       "                                          raw_avi_path  \n",
       "0    /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "152  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "304  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "456  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "608  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_video_df = TS_reader1_df_filtered.drop_duplicates(subset=['study_id'])\n",
    "TS_reader2_video_df = TS_reader2_df_filtered.drop_duplicates(subset=['study_id'])\n",
    "\n",
    "print(len(TS_reader1_video_df))\n",
    "print(len(TS_reader2_video_df))\n",
    "TS_reader1_video_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "TS_clip_root_paths = '/data2/hoon2/LUS_Dataset/clip_avi_temporally_separated_dataset'\n",
    "\n",
    "TS_clip_paths = glob(f'{TS_clip_root_paths}/*.avi')\n",
    "\n",
    "print(len(TS_clip_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(start, end=None):\n",
    "    # If only one number is provided, revalue_counts list with that number.\n",
    "    if end is None:\n",
    "        return [int(start)]\n",
    "    # If start and end are provided, return a list with numbers from start to end, inclusive.\n",
    "    else:\n",
    "\n",
    "        return list(range(int(start), int(end) + 1))\n",
    "#         return list(range(int(start)-1, int(end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lbl_range_dict(df, lbl_name):\n",
    "    lbl_dict = {}\n",
    "    for si, lbl in df[['study_id',lbl_name]].values:\n",
    "        lbl_range_ls = []\n",
    "        if pd.isna(lbl):\n",
    "            lbl_dict[si] = [[0]]\n",
    "        else:\n",
    "            refined_lbl = lbl.strip()\n",
    "            refined_lbl_ls = refined_lbl.split(',')\n",
    "            for r_lbl in refined_lbl_ls:\n",
    "                lbl_range = re.split(r'[_-]', r_lbl)\n",
    "                lbl_range_ls.append(create_list(*lbl_range))   \n",
    "            lbl_dict[si] = lbl_range_ls  \n",
    "    return lbl_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeler 1 \n",
    "al_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'A-line')\n",
    "bl_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'B-line')\n",
    "cb_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'Confluent B-line')\n",
    "c_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'Consolidation')\n",
    "pe_lbl_dict1 = gen_lbl_range_dict(TS_reader1_df_filtered, 'Pleural effusion')\n",
    "\n",
    "# labler 2\n",
    "al_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'A-line')\n",
    "bl_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'B-line')\n",
    "cb_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'Confluent B-line')\n",
    "c_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'Consolidation')\n",
    "pe_lbl_dict2 = gen_lbl_range_dict(TS_reader2_df_filtered, 'Pleural effusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pleural effusion</th>\n",
       "      <th>Lung sliding</th>\n",
       "      <th>Lung Ultrasound Score</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3_c</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "11               2   52426014         8   20240712     video         NaN   \n",
       "\n",
       "   A-line B-line Confluent B-line Consolidation Pleural effusion  \\\n",
       "11   1_33  1_152           38_152       117_152              NaN   \n",
       "\n",
       "    Lung sliding Lung Ultrasound Score  LUS score align    study_id  \n",
       "11             0                   3_c                0  52426014_8  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_df[TS_reader1_df['study_id'] == '52426014_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>...</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "      <th>FileName</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_avi_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2</td>\n",
       "      <td>52426014</td>\n",
       "      <td>8</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_33</td>\n",
       "      <td>1_152</td>\n",
       "      <td>38_152</td>\n",
       "      <td>117_152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>52426014_8</td>\n",
       "      <td>52426014_00008_133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "1672               2   52426014         8   20240712     video         NaN   \n",
       "1673               2   52426014         8   20240712     video         NaN   \n",
       "1674               2   52426014         8   20240712     video         NaN   \n",
       "1675               2   52426014         8   20240712     video         NaN   \n",
       "1676               2   52426014         8   20240712     video         NaN   \n",
       "...              ...        ...       ...        ...       ...         ...   \n",
       "1819               2   52426014         8   20240712     video         NaN   \n",
       "1820               2   52426014         8   20240712     video         NaN   \n",
       "1821               2   52426014         8   20240712     video         NaN   \n",
       "1822               2   52426014         8   20240712     video         NaN   \n",
       "1823               2   52426014         8   20240712     video         NaN   \n",
       "\n",
       "     A-line B-line Confluent B-line Consolidation  ... LUS score align  \\\n",
       "1672   1_33  1_152           38_152       117_152  ...               0   \n",
       "1673   1_33  1_152           38_152       117_152  ...               0   \n",
       "1674   1_33  1_152           38_152       117_152  ...               0   \n",
       "1675   1_33  1_152           38_152       117_152  ...               0   \n",
       "1676   1_33  1_152           38_152       117_152  ...               0   \n",
       "...     ...    ...              ...           ...  ...             ...   \n",
       "1819   1_33  1_152           38_152       117_152  ...               0   \n",
       "1820   1_33  1_152           38_152       117_152  ...               0   \n",
       "1821   1_33  1_152           38_152       117_152  ...               0   \n",
       "1822   1_33  1_152           38_152       117_152  ...               0   \n",
       "1823   1_33  1_152           38_152       117_152  ...               0   \n",
       "\n",
       "        study_id            FileName  A-line_lbl B-line_lbl  \\\n",
       "1672  52426014_8   52426014_00008_76           0          1   \n",
       "1673  52426014_8  52426014_00008_147           0          1   \n",
       "1674  52426014_8   52426014_00008_45           0          1   \n",
       "1675  52426014_8   52426014_00008_83           0          1   \n",
       "1676  52426014_8  52426014_00008_107           0          1   \n",
       "...          ...                 ...         ...        ...   \n",
       "1819  52426014_8   52426014_00008_51           0          1   \n",
       "1820  52426014_8  52426014_00008_101           0          1   \n",
       "1821  52426014_8   52426014_00008_10           1          1   \n",
       "1822  52426014_8   52426014_00008_40           0          1   \n",
       "1823  52426014_8  52426014_00008_133           0          1   \n",
       "\n",
       "     Confluent B-line_lbl  Consolidation_lbl  Pleural effusion_lbl  \\\n",
       "1672                    1                  0                     0   \n",
       "1673                    1                  1                     0   \n",
       "1674                    1                  0                     0   \n",
       "1675                    1                  0                     0   \n",
       "1676                    1                  0                     0   \n",
       "...                   ...                ...                   ...   \n",
       "1819                    1                  0                     0   \n",
       "1820                    1                  0                     0   \n",
       "1821                    0                  0                     0   \n",
       "1822                    1                  0                     0   \n",
       "1823                    1                  1                     0   \n",
       "\n",
       "                                               img_path  \\\n",
       "1672  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1673  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1674  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1675  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1676  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "...                                                 ...   \n",
       "1819  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1820  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1821  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1822  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "1823  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "\n",
       "                                           raw_avi_path  \n",
       "1672  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1673  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1674  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1675  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1676  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "...                                                 ...  \n",
       "1819  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1820  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1821  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1822  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "1823  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "\n",
       "[152 rows x 23 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_df_filtered[TS_reader1_df_filtered['study_id'] == '52426014_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>...</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "      <th>FileName</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_avi_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>3</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71_127</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_3</td>\n",
       "      <td>44937986_00003_84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>4</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_4</td>\n",
       "      <td>44937986_00004_19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>5</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36_48</td>\n",
       "      <td>46_61</td>\n",
       "      <td>126_130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_5</td>\n",
       "      <td>44937986_00005_88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>6</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37_47</td>\n",
       "      <td>47_58</td>\n",
       "      <td>126_130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_6</td>\n",
       "      <td>44937986_00006_33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "0                 1   44937986         2   20240712     video         NaN   \n",
       "152               1   44937986         3   20240712     video         NaN   \n",
       "304               1   44937986         4   20240712     video         NaN   \n",
       "456               1   44937986         5   20240712     video         NaN   \n",
       "608               1   44937986         6   20240712     video         NaN   \n",
       "\n",
       "    A-line B-line Confluent B-line Consolidation  ... LUS score align  \\\n",
       "0    1_152    NaN              NaN           NaN  ...               1   \n",
       "152    NaN    NaN              NaN        71_127  ...               1   \n",
       "304    NaN    NaN              NaN         1_152  ...               1   \n",
       "456  36_48  46_61          126_130           NaN  ...               0   \n",
       "608  37_47  47_58          126_130           NaN  ...               0   \n",
       "\n",
       "       study_id            FileName  A-line_lbl B-line_lbl  \\\n",
       "0    44937986_2  44937986_00002_135           1          0   \n",
       "152  44937986_3   44937986_00003_84           0          0   \n",
       "304  44937986_4   44937986_00004_19           0          0   \n",
       "456  44937986_5   44937986_00005_88           0          0   \n",
       "608  44937986_6   44937986_00006_33           0          0   \n",
       "\n",
       "    Confluent B-line_lbl  Consolidation_lbl  Pleural effusion_lbl  \\\n",
       "0                      0                  0                     0   \n",
       "152                    0                  1                     1   \n",
       "304                    0                  1                     1   \n",
       "456                    0                  0                     0   \n",
       "608                    0                  0                     0   \n",
       "\n",
       "                                              img_path  \\\n",
       "0    /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "152  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "304  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "456  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "608  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "\n",
       "                                          raw_avi_path  \n",
       "0    /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "152  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "304  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "456  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "608  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader1_video_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient number</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Point Zone</th>\n",
       "      <th>A-line</th>\n",
       "      <th>B-line</th>\n",
       "      <th>Confluent B-line</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>...</th>\n",
       "      <th>LUS score align</th>\n",
       "      <th>study_id</th>\n",
       "      <th>FileName</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_avi_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_2</td>\n",
       "      <td>44937986_00002_135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>3</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87_115</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_3</td>\n",
       "      <td>44937986_00003_84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>4</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59_89</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44937986_4</td>\n",
       "      <td>44937986_00004_19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>5</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47_60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_5</td>\n",
       "      <td>44937986_00005_88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1</td>\n",
       "      <td>44937986</td>\n",
       "      <td>6</td>\n",
       "      <td>20240712</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92_99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44937986_6</td>\n",
       "      <td>44937986_00006_33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/temporally_separated_...</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/processed_temporally_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient number  PatientID  Data_idx  StudyDate Data_type  Point Zone  \\\n",
       "0                 1   44937986         2   20240712     video         NaN   \n",
       "152               1   44937986         3   20240712     video         NaN   \n",
       "304               1   44937986         4   20240712     video         NaN   \n",
       "456               1   44937986         5   20240712     video         NaN   \n",
       "608               1   44937986         6   20240712     video         NaN   \n",
       "\n",
       "    A-line B-line Confluent B-line Consolidation  ... LUS score align  \\\n",
       "0    1_152    NaN              NaN           NaN  ...               1   \n",
       "152    NaN    NaN              NaN        87_115  ...               1   \n",
       "304    NaN    NaN              NaN         59_89  ...               1   \n",
       "456    NaN  47_60              NaN           NaN  ...               0   \n",
       "608    NaN  92_99              NaN           NaN  ...               0   \n",
       "\n",
       "       study_id            FileName  A-line_lbl B-line_lbl  \\\n",
       "0    44937986_2  44937986_00002_135           1          0   \n",
       "152  44937986_3   44937986_00003_84           0          0   \n",
       "304  44937986_4   44937986_00004_19           0          0   \n",
       "456  44937986_5   44937986_00005_88           0          0   \n",
       "608  44937986_6   44937986_00006_33           0          0   \n",
       "\n",
       "    Confluent B-line_lbl  Consolidation_lbl  Pleural effusion_lbl  \\\n",
       "0                      0                  0                     0   \n",
       "152                    0                  0                     0   \n",
       "304                    0                  0                     0   \n",
       "456                    0                  0                     0   \n",
       "608                    0                  0                     0   \n",
       "\n",
       "                                              img_path  \\\n",
       "0    /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "152  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "304  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "456  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "608  /data2/hoon2/LUS_Dataset/temporally_separated_...   \n",
       "\n",
       "                                          raw_avi_path  \n",
       "0    /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "152  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "304  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "456  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "608  /data2/hoon2/LUS_Dataset/processed_temporally_...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_reader2_video_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256_clip_path</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>60916943</td>\n",
       "      <td>60916943_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>80306634_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>54258868</td>\n",
       "      <td>54258868_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       256_clip_path PatientID    study_id\n",
       "0  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  52426014  52426014_7\n",
       "1  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  60916943  60916943_4\n",
       "2  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  52426014  52426014_5\n",
       "3  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  80306634  80306634_6\n",
       "4  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  54258868  54258868_4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 경로에서 patientID 추출\n",
    "patient_ids = [path.split('/')[-1].split('_')[0] for path in TS_clip_paths]\n",
    "study_ids = []\n",
    "for path in TS_clip_paths:\n",
    "    info = path.split('/')[-1].split('.')[0].split('_')\n",
    "    patient_id = info[0]\n",
    "    study_id = str(int(info[1]))  \n",
    "    study_id = f\"{patient_id}_{study_id}\"\n",
    "    study_ids.append(study_id)\n",
    "    \n",
    "# labeler 1\n",
    "TS_reader1_video_df_ = pd.DataFrame({\n",
    "    '256_clip_path': TS_clip_paths,\n",
    "    'PatientID': patient_ids,\n",
    "    'study_id': study_ids\n",
    "})\n",
    "\n",
    "# labeler 2\n",
    "TS_reader2_video_df_ = pd.DataFrame({\n",
    "    '256_clip_path': TS_clip_paths,\n",
    "    'PatientID': patient_ids,\n",
    "    'study_id': study_ids\n",
    "})\n",
    "\n",
    "TS_reader1_video_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_dicts1 = {\n",
    "    'A-line_lbl': al_lbl_dict1,\n",
    "    'B-line_lbl': bl_lbl_dict1,\n",
    "    'Confluent B-line_lbl': cb_lbl_dict1,\n",
    "    'Consolidation_lbl' : c_lbl_dict1,\n",
    "    'Pleural effusion_lbl':pe_lbl_dict1\n",
    "}\n",
    "\n",
    "lbl_dicts2 = {\n",
    "    'A-line_lbl': al_lbl_dict2,\n",
    "    'B-line_lbl': bl_lbl_dict2,\n",
    "    'Confluent B-line_lbl': cb_lbl_dict2,\n",
    "    'Consolidation_lbl' : c_lbl_dict2,\n",
    "    'Pleural effusion_lbl':pe_lbl_dict2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_labels_for_avi(df, lbl_dicts):\n",
    "    # 각 레이블(아티팩트)에 대해 데이터프레임에 열을 추가하고, 초기값을 0으로 설정합니다.\n",
    "    for lbl_name in lbl_dicts.keys():\n",
    "        df[lbl_name] = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        clip_path = row['256_clip_path']\n",
    "        # 파일명에서 프레임 범위 추출\n",
    "        _, start_frame, end_frame = clip_path.split('/')[-1].split('.')[0].split('_')[-3:]\n",
    "        start_frame, end_frame = int(start_frame), int(end_frame)\n",
    "\n",
    "        study_id = row['study_id']\n",
    "        \n",
    "        # 모든 레이블 사전을 순회\n",
    "        for lbl_name, lbl_dict in lbl_dicts.items():\n",
    "            \n",
    "            lbl_ranges = lbl_dict.get(study_id, [])\n",
    "    \n",
    "            if lbl_ranges == [[0]]:\n",
    "                continue\n",
    "            # 레이블 영역 리스트를 순회하며 현재 avi 파일의 프레임 범위와 겹치는지 확인합니다.\n",
    "            for lbl_range in lbl_ranges:\n",
    "                '''\n",
    "                # 현재 레이블 영역과 avi 파일의 프레임 범위가 겹치는지 확인\n",
    "                    - 시작 프레임이 레이블 범위 내에 있는 경우\n",
    "                    - 끝 프레임이 레이블 범위 내에 있는 경우\n",
    "                    - 레이블 범위가 시작 프레임과 끝 프레임 사이에 완전히 포함되는 경우\n",
    "                '''\n",
    "                if (lbl_range[0] <= start_frame <= lbl_range[-1]) or (lbl_range[0] <= end_frame <= lbl_range[-1]) or (start_frame <= lbl_range[0] and end_frame >= lbl_range[-1]):\n",
    "                    df.at[idx, lbl_name] = 1  # 겹침이 확인되면 해당 레이블 열에 1을 표시합니다.\n",
    "                    break  # 하나의 영역이라도 겹치면 다음 레이블로 넘어갑니다.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  152]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_dicts1['Confluent B-line_lbl'].get('52426014_8', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n",
      "392\n"
     ]
    }
   ],
   "source": [
    "TS_clip_reader1_final_df = check_labels_for_avi(TS_reader1_video_df_, lbl_dicts1)\n",
    "TS_clip_reader2_final_df = check_labels_for_avi(TS_reader2_video_df_, lbl_dicts2)\n",
    "\n",
    "print(len(TS_clip_reader1_final_df))\n",
    "print(len(TS_clip_reader2_final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256_clip_path</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>study_id</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>60916943</td>\n",
       "      <td>60916943_4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>80306634_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>54258868</td>\n",
       "      <td>54258868_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>61398238</td>\n",
       "      <td>61398238_7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>14184938</td>\n",
       "      <td>14184938_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>37292786</td>\n",
       "      <td>37292786_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>61308381</td>\n",
       "      <td>61308381_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>44937986_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         256_clip_path PatientID    study_id  \\\n",
       "0    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  52426014  52426014_7   \n",
       "1    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  60916943  60916943_4   \n",
       "2    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  52426014  52426014_5   \n",
       "3    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  80306634  80306634_6   \n",
       "4    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  54258868  54258868_4   \n",
       "..                                                 ...       ...         ...   \n",
       "387  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  61398238  61398238_7   \n",
       "388  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  14184938  14184938_3   \n",
       "389  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  37292786  37292786_4   \n",
       "390  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  61308381  61308381_2   \n",
       "391  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  44937986  44937986_5   \n",
       "\n",
       "     A-line_lbl  B-line_lbl  Confluent B-line_lbl  Consolidation_lbl  \\\n",
       "0             1           1                     0                  1   \n",
       "1             0           1                     0                  0   \n",
       "2             1           1                     1                  0   \n",
       "3             1           0                     0                  0   \n",
       "4             1           0                     0                  0   \n",
       "..          ...         ...                   ...                ...   \n",
       "387           0           1                     0                  0   \n",
       "388           1           0                     0                  0   \n",
       "389           1           1                     0                  0   \n",
       "390           1           0                     0                  0   \n",
       "391           0           0                     1                  0   \n",
       "\n",
       "     Pleural effusion_lbl  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "387                     0  \n",
       "388                     0  \n",
       "389                     0  \n",
       "390                     0  \n",
       "391                     0  \n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_clip_reader1_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256_clip_path</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>study_id</th>\n",
       "      <th>A-line_lbl</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Consolidation_lbl</th>\n",
       "      <th>Pleural effusion_lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>60916943</td>\n",
       "      <td>60916943_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>80306634_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>54258868</td>\n",
       "      <td>54258868_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>61398238</td>\n",
       "      <td>61398238_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>14184938</td>\n",
       "      <td>14184938_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>37292786</td>\n",
       "      <td>37292786_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>61308381</td>\n",
       "      <td>61308381_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>44937986_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         256_clip_path PatientID    study_id  \\\n",
       "0    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  52426014  52426014_7   \n",
       "1    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  60916943  60916943_4   \n",
       "2    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  52426014  52426014_5   \n",
       "3    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  80306634  80306634_6   \n",
       "4    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  54258868  54258868_4   \n",
       "..                                                 ...       ...         ...   \n",
       "387  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  61398238  61398238_7   \n",
       "388  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  14184938  14184938_3   \n",
       "389  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  37292786  37292786_4   \n",
       "390  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  61308381  61308381_2   \n",
       "391  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  44937986  44937986_5   \n",
       "\n",
       "     A-line_lbl  B-line_lbl  Confluent B-line_lbl  Consolidation_lbl  \\\n",
       "0             0           0                     0                  0   \n",
       "1             0           0                     0                  0   \n",
       "2             0           0                     0                  0   \n",
       "3             1           0                     0                  0   \n",
       "4             0           0                     0                  1   \n",
       "..          ...         ...                   ...                ...   \n",
       "387           0           0                     0                  0   \n",
       "388           0           0                     0                  0   \n",
       "389           0           0                     1                  0   \n",
       "390           1           0                     0                  0   \n",
       "391           0           0                     0                  0   \n",
       "\n",
       "     Pleural effusion_lbl  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "387                     0  \n",
       "388                     0  \n",
       "389                     0  \n",
       "390                     0  \n",
       "391                     0  \n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_clip_reader2_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_clip_reader1_final_df.to_csv(f\"/data2/hoon2/LUS_Dataset/csv_files/temporally_separated_test_set/clip/5_artifacts/temporally_separated_test_reader1.csv\", index=False)\n",
    "TS_clip_reader2_final_df.to_csv(f\"/data2/hoon2/LUS_Dataset/csv_files/temporally_separated_test_set/clip/5_artifacts/temporally_separated_test_reader2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare AI vs two Clinicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data_type = 'internal_test'\n",
    "data_type = 'temporally_separated_test'\n",
    "\n",
    "fold_num = 0\n",
    "\n",
    "# AI model output\n",
    "LUV_Net_outputs = pd.read_csv(f'/data2/hoon2/Results/model_output_csv/video_level/{data_type}/densenet_161/5_artifacts_batch4_fold_{fold_num}_LUV_Net_8head_13ksize_output.csv')\n",
    "\n",
    "# reader 1 label\n",
    "reader1_gt = pd.read_csv('/data2/hoon2/LUS_Dataset/csv_files/temporally_separated_test_set/clip/5_artifacts/temporally_separated_test_reader1.csv')\n",
    "\n",
    "# reader 2 label\n",
    "reader2_gt = pd.read_csv('/data2/hoon2/LUS_Dataset/csv_files/temporally_separated_test_set/clip/5_artifacts/temporally_separated_test_reader2.csv')\n",
    "\n",
    "# expert label\n",
    "expert_gt = pd.read_csv(f'/data2/hoon2/Results/model_output_csv/video_level/{data_type}/5_artifacts_video_level_expert_gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LUVM_A-line</th>\n",
       "      <th>LUVM_total-B-line</th>\n",
       "      <th>LUVM_Consolidation</th>\n",
       "      <th>LUVM_Pleural effusion</th>\n",
       "      <th>clip_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935229</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.014675</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.936214</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.017229</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946519</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935421</td>\n",
       "      <td>0.069799</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933353</td>\n",
       "      <td>0.053146</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.063993</td>\n",
       "      <td>0.775873</td>\n",
       "      <td>0.033005</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.063981</td>\n",
       "      <td>0.672396</td>\n",
       "      <td>0.035775</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.049650</td>\n",
       "      <td>0.602211</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.080733</td>\n",
       "      <td>0.696348</td>\n",
       "      <td>0.029782</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.176628</td>\n",
       "      <td>0.532650</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LUVM_A-line  LUVM_total-B-line  LUVM_Consolidation  \\\n",
       "0       0.935229           0.056365            0.019443   \n",
       "1       0.936214           0.050234            0.021592   \n",
       "2       0.946519           0.053254            0.017268   \n",
       "3       0.935421           0.069799            0.017375   \n",
       "4       0.933353           0.053146            0.020744   \n",
       "..           ...                ...                 ...   \n",
       "387     0.063993           0.775873            0.033005   \n",
       "388     0.063981           0.672396            0.035775   \n",
       "389     0.049650           0.602211            0.056109   \n",
       "390     0.080733           0.696348            0.029782   \n",
       "391     0.176628           0.532650            0.031243   \n",
       "\n",
       "     LUVM_Pleural effusion                                            clip_id  \n",
       "0                 0.014675  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "1                 0.017229  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "2                 0.014103  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "3                 0.013095  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "4                 0.014834  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "..                     ...                                                ...  \n",
       "387               0.004171  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "388               0.004917  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "389               0.007301  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "390               0.005065  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "391               0.005212  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...  \n",
       "\n",
       "[392 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_id_lst = [id for id in expert_gt['clip_id']]\n",
    "LUV_Net_outputs['clip_id'] = clip_id_lst\n",
    "LUV_Net_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble results 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_thresholds_by_fold = {\n",
    "    0: [0.22634831, 0.15914528, 0.25003922, 0.050135028],\n",
    "    1: [0.40295565, 0.088446975, 0.24804993, 0.11546604],\n",
    "    2: [0.00018062566, 0.35014683, 0.4687046, 0.105172224],\n",
    "    3: [0.2670747, 0.18359607, 0.24848126, 0.12985016],\n",
    "    4: [0.15066153, 0.109094806, 0.4810904, 0.27746475]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_ensemble_with_fold_thresholds(thresholds_by_fold, clip_id_lst):\n",
    "    pred_columns = ['LUVM_A-line', 'LUVM_total-B-line', 'LUVM_Consolidation', 'LUVM_Pleural effusion']\n",
    "    binary_preds = []\n",
    "\n",
    "    for fold_num in range(5):\n",
    "        path = f'/data2/hoon2/Results/model_output_csv/video_level/temporally_separated_test/densenet_161/5_artifacts_batch4_fold_{fold_num}_LUV_Net_8head_13ksize_output.csv'\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        bin_df = pd.DataFrame()\n",
    "        for i, col in enumerate(pred_columns):\n",
    "            thres = thresholds_by_fold[fold_num][i]\n",
    "            bin_df[col] = (df[col] >= thres).astype(int)\n",
    "        \n",
    "        binary_preds.append(bin_df)\n",
    "\n",
    "    # 다수결 voting: 각 label에 대해 5개 중 3개 이상이 1이면 1로 간주\n",
    "    stacked_bin = np.stack([df.values for df in binary_preds], axis=-1)  # (num_samples, num_classes, 5)\n",
    "    majority_votes = (stacked_bin.sum(axis=-1) >= 3).astype(int)\n",
    "\n",
    "    result_df = pd.DataFrame(majority_votes, columns=pred_columns)\n",
    "    result_df.insert(0, 'clip_id', clip_id_lst)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>LUVM_A-line</th>\n",
       "      <th>LUVM_total-B-line</th>\n",
       "      <th>LUVM_Consolidation</th>\n",
       "      <th>LUVM_Pleural effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clip_id  LUVM_A-line  \\\n",
       "0  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1   \n",
       "1  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1   \n",
       "2  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1   \n",
       "3  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1   \n",
       "4  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1   \n",
       "\n",
       "   LUVM_total-B-line  LUVM_Consolidation  LUVM_Pleural effusion  \n",
       "0                  1                   0                      0  \n",
       "1                  0                   0                      0  \n",
       "2                  0                   0                      0  \n",
       "3                  1                   0                      0  \n",
       "4                  1                   0                      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_df = voting_ensemble_with_fold_thresholds(thresholds_by_fold = ai_thresholds_by_fold, clip_id_lst = clip_id_lst)\n",
    "print(len(ensemble_df))\n",
    "ensemble_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data2/hoon2/LUS_Dataset/clip_avi_temporally_separated_dataset/44937986_00002_1_30.avi'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df['clip_id'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patient_data_idx(clip_path):\n",
    "    try:\n",
    "        filename = clip_path.split('/')[-1]\n",
    "        parts = filename.split('_')\n",
    "        patient_id = int(parts[0])\n",
    "        data_idx = int(parts[1])\n",
    "        return pd.Series([patient_id, data_idx])\n",
    "    except:\n",
    "        return pd.Series([None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expert ID 추출\n",
    "expert_gt[[\"PatientID\", \"Data_idx\"]] = expert_gt[\"clip_id\"].apply(extract_patient_data_idx)\n",
    "expert_gt.head()\n",
    "len(expert_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PatientID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PatientID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m expert_gt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudy_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatientID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m expert_gt\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m----> 2\u001b[0m ensemble_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudy_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatientID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m ensemble_df\u001b[38;5;241m.\u001b[39miterrows()]\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m expert_gt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudy_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatientID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m expert_gt\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m----> 2\u001b[0m ensemble_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudy_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatientID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m ensemble_df\u001b[38;5;241m.\u001b[39miterrows()]\n",
      "File \u001b[0;32m~/anaconda3/envs/pda/lib/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/envs/pda/lib/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/envs/pda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PatientID'"
     ]
    }
   ],
   "source": [
    "expert_gt['study_id'] = [ f\"{row['PatientID']}_{row['Data_idx']}\" for idx, row in expert_gt.iterrows()]\n",
    "ensemble_df['study_id'] = [ f\"{row['PatientID']}_{row['Data_idx']}\" for idx, row in ensemble_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader1/2: ID 추출 및 total-B-line 생성, 컬럼명 변경\n",
    "reader1_gt[[\"PatientID\", \"Data_idx\"]] = reader1_gt[\"256_clip_path\"].apply(extract_patient_data_idx)\n",
    "reader2_gt[[\"PatientID\", \"Data_idx\"]] = reader2_gt[\"256_clip_path\"].apply(extract_patient_data_idx)\n",
    "\n",
    "reader1_gt[\"Reader1_total-B-line\"] = reader1_gt[\"B-line_lbl\"] | reader1_gt[\"Confluent B-line_lbl\"]\n",
    "reader2_gt[\"Reader2_total-B-line\"] = reader2_gt[\"B-line_lbl\"] | reader2_gt[\"Confluent B-line_lbl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LUV_Net_outputs: AI result\n",
    "    - fold 0 threshold of each labels: [0.22634831, 0.15914528, 0.25003922, 0.050135028]\n",
    "    - fold 1 threshold of each labels: [0.40295565, 0.088446975, 0.24804993, 0.11546604]\n",
    "    - fold 2 threshold of each labels: [0.00018062566, 0.35014683, 0.4687046, 0.105172224]\n",
    "    - fold 3 threshold of each labels: [0.2670747, 0.18359607, 0.24848126, 0.12985016]\n",
    "    - fold 4 threshold of each labels: [0.15066153, 0.109094806, 0.4810904, 0.27746475]\n",
    "2. models_gt: expert outputs\n",
    "3. TS_clip_reader1_final_df: clinicians 1 results\n",
    "4. TS_clip_reader2_final_df: clinicians 2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_thresholds_by_fold = {\n",
    "    0: [0.22634831, 0.15914528, 0.25003922, 0.050135028],\n",
    "    1: [0.40295565, 0.088446975, 0.24804993, 0.11546604],\n",
    "    2: [0.00018062566, 0.35014683, 0.4687046, 0.105172224],\n",
    "    3: [0.2670747, 0.18359607, 0.24848126, 0.12985016],\n",
    "    4: [0.15066153, 0.109094806, 0.4810904, 0.27746475]\n",
    "}\n",
    "\n",
    "thresholds = ai_thresholds_by_fold[fold_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LUVM_A-line</th>\n",
       "      <th>LUVM_total-B-line</th>\n",
       "      <th>LUVM_Consolidation</th>\n",
       "      <th>LUVM_Pleural effusion</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>AI_A-line</th>\n",
       "      <th>AI_total-B-line</th>\n",
       "      <th>AI_Consolidation</th>\n",
       "      <th>AI_Pleural effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935229</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.014675</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.936214</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.017229</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946519</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935421</td>\n",
       "      <td>0.069799</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933353</td>\n",
       "      <td>0.053146</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.063993</td>\n",
       "      <td>0.775873</td>\n",
       "      <td>0.033005</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.063981</td>\n",
       "      <td>0.672396</td>\n",
       "      <td>0.035775</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.049650</td>\n",
       "      <td>0.602211</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.080733</td>\n",
       "      <td>0.696348</td>\n",
       "      <td>0.029782</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.176628</td>\n",
       "      <td>0.532650</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LUVM_A-line  LUVM_total-B-line  LUVM_Consolidation  \\\n",
       "0       0.935229           0.056365            0.019443   \n",
       "1       0.936214           0.050234            0.021592   \n",
       "2       0.946519           0.053254            0.017268   \n",
       "3       0.935421           0.069799            0.017375   \n",
       "4       0.933353           0.053146            0.020744   \n",
       "..           ...                ...                 ...   \n",
       "387     0.063993           0.775873            0.033005   \n",
       "388     0.063981           0.672396            0.035775   \n",
       "389     0.049650           0.602211            0.056109   \n",
       "390     0.080733           0.696348            0.029782   \n",
       "391     0.176628           0.532650            0.031243   \n",
       "\n",
       "     LUVM_Pleural effusion                                            clip_id  \\\n",
       "0                 0.014675  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "1                 0.017229  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "2                 0.014103  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "3                 0.013095  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "4                 0.014834  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "..                     ...                                                ...   \n",
       "387               0.004171  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "388               0.004917  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "389               0.007301  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "390               0.005065  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "391               0.005212  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   \n",
       "\n",
       "     PatientID  Data_idx  AI_A-line  AI_total-B-line  AI_Consolidation  \\\n",
       "0     44937986         2          1                0                 0   \n",
       "1     44937986         2          1                0                 0   \n",
       "2     44937986         2          1                0                 0   \n",
       "3     44937986         2          1                0                 0   \n",
       "4     44937986         2          1                0                 0   \n",
       "..         ...       ...        ...              ...               ...   \n",
       "387   80306634         7          0                1                 0   \n",
       "388   80306634         7          0                1                 0   \n",
       "389   80306634         7          0                1                 0   \n",
       "390   80306634         7          0                1                 0   \n",
       "391   80306634         7          0                1                 0   \n",
       "\n",
       "     AI_Pleural effusion  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "..                   ...  \n",
       "387                    0  \n",
       "388                    0  \n",
       "389                    0  \n",
       "390                    0  \n",
       "391                    0  \n",
       "\n",
       "[392 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI: ID 추출 및 threshold에 따라 이진화\n",
    "LUV_Net_outputs[[\"PatientID\", \"Data_idx\"]] = LUV_Net_outputs[\"clip_id\"].apply(extract_patient_data_idx)\n",
    "LUV_Net_outputs[\"AI_A-line\"] = (LUV_Net_outputs[\"LUVM_A-line\"] > thresholds[0]).astype(int)\n",
    "LUV_Net_outputs[\"AI_total-B-line\"] = (LUV_Net_outputs[\"LUVM_total-B-line\"] > thresholds[1]).astype(int)\n",
    "LUV_Net_outputs[\"AI_Consolidation\"] = (LUV_Net_outputs[\"LUVM_Consolidation\"] > thresholds[2]).astype(int)\n",
    "LUV_Net_outputs[\"AI_Pleural effusion\"] = (LUV_Net_outputs[\"LUVM_Pleural effusion\"] > thresholds[3]).astype(int)\n",
    "\n",
    "LUV_Net_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_gt['study_id'] = [ f\"{row['PatientID']}_{row['Data_idx']}\" for idx, row in expert_gt.iterrows()]\n",
    "LUV_Net_outputs['study_id'] = [ f\"{row['PatientID']}_{row['Data_idx']}\" for idx, row in LUV_Net_outputs.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LUVM_A-line</th>\n",
       "      <th>LUVM_total-B-line</th>\n",
       "      <th>LUVM_Consolidation</th>\n",
       "      <th>LUVM_Pleural effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935229</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.014675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.936214</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.017229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946519</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.014103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935421</td>\n",
       "      <td>0.069799</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.013095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933353</td>\n",
       "      <td>0.053146</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.014834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LUVM_A-line  LUVM_total-B-line  LUVM_Consolidation  LUVM_Pleural effusion\n",
       "0     0.935229           0.056365            0.019443               0.014675\n",
       "1     0.936214           0.050234            0.021592               0.017229\n",
       "2     0.946519           0.053254            0.017268               0.014103\n",
       "3     0.935421           0.069799            0.017375               0.013095\n",
       "4     0.933353           0.053146            0.020744               0.014834"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LUV_Net_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader1/2: ID 추출 및 total-B-line 생성, 컬럼명 변경\n",
    "reader1_gt[[\"PatientID\", \"Data_idx\"]] = reader1_gt[\"256_clip_path\"].apply(extract_patient_data_idx)\n",
    "reader2_gt[[\"PatientID\", \"Data_idx\"]] = reader2_gt[\"256_clip_path\"].apply(extract_patient_data_idx)\n",
    "\n",
    "reader1_gt[\"Reader1_total-B-line\"] = reader1_gt[\"B-line_lbl\"] | reader1_gt[\"Confluent B-line_lbl\"]\n",
    "reader2_gt[\"Reader2_total-B-line\"] = reader2_gt[\"B-line_lbl\"] | reader2_gt[\"Confluent B-line_lbl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LUV_Net_outputs.to_csv(f'/data2/hoon2/Results/model_output_csv/video_level/temporally_separated_test/5_artifacts_fold_{fold_num}_video_level_ai.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader1_gt = reader1_gt.rename(columns={\n",
    "    \"A-line_lbl\": \"Reader1_A-line\",\n",
    "    \"Consolidation_lbl\": \"Reader1_Consolidation\",\n",
    "    \"Pleural effusion_lbl\": \"Reader1_Pleural effusion\"\n",
    "})\n",
    "reader2_gt = reader2_gt.rename(columns={\n",
    "    \"A-line_lbl\": \"Reader2_A-line\",\n",
    "    \"Consolidation_lbl\": \"Reader2_Consolidation\",\n",
    "    \"Pleural effusion_lbl\": \"Reader2_Pleural effusion\"\n",
    "})\n",
    "\n",
    "# Expert 컬럼명 정리\n",
    "expert_gt = expert_gt.rename(columns={\n",
    "    \"A-line\": \"Expert_A-line\",\n",
    "    \"total-B-line\": \"Expert_total-B-line\",\n",
    "    \"Consolidation\": \"Expert_Consolidation\",\n",
    "    \"Pleural effusion\": \"Expert_Pleural effusion\"\n",
    "})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert DataFrame rows: 392\n",
      "Reader1 DataFrame rows: 392\n",
      "Reader2 DataFrame rows: 392\n",
      "LUV_Net outputs rows: 392\n",
      "Unique (PatientID, Data_idx) in Expert DataFrame: 56\n",
      "Unique (PatientID, Data_idx) in Reader1 DataFrame: 56\n",
      "Unique (PatientID, Data_idx) in Reader2 DataFrame: 56\n",
      "Unique (PatientID, Data_idx) in LUV_Net outputs: 56\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in each original DataFrame\n",
    "print(\"Expert DataFrame rows:\", len(expert_gt))\n",
    "print(\"Reader1 DataFrame rows:\", len(reader1_gt))\n",
    "print(\"Reader2 DataFrame rows:\", len(reader2_gt))\n",
    "print(\"LUV_Net outputs rows:\", len(LUV_Net_outputs))\n",
    "\n",
    "# Check unique combinations of PatientID and Data_idx in each DataFrame\n",
    "print(\"Unique (PatientID, Data_idx) in Expert DataFrame:\", expert_gt[[\"PatientID\", \"Data_idx\"]].drop_duplicates().shape[0])\n",
    "print(\"Unique (PatientID, Data_idx) in Reader1 DataFrame:\", reader1_gt[[\"PatientID\", \"Data_idx\"]].drop_duplicates().shape[0])\n",
    "print(\"Unique (PatientID, Data_idx) in Reader2 DataFrame:\", reader2_gt[[\"PatientID\", \"Data_idx\"]].drop_duplicates().shape[0])\n",
    "print(\"Unique (PatientID, Data_idx) in LUV_Net outputs:\", LUV_Net_outputs[[\"PatientID\", \"Data_idx\"]].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Reader2_A-line</th>\n",
       "      <th>B-line_lbl</th>\n",
       "      <th>Confluent B-line_lbl</th>\n",
       "      <th>Reader2_Consolidation</th>\n",
       "      <th>Reader2_Pleural effusion</th>\n",
       "      <th>Data_idx</th>\n",
       "      <th>Reader2_total-B-line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>60916943</td>\n",
       "      <td>60916943_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>52426014</td>\n",
       "      <td>52426014_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>80306634</td>\n",
       "      <td>80306634_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>54258868</td>\n",
       "      <td>54258868_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>61398238</td>\n",
       "      <td>61398238_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>14184938</td>\n",
       "      <td>14184938_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>37292786</td>\n",
       "      <td>37292786_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>61308381</td>\n",
       "      <td>61308381_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>44937986</td>\n",
       "      <td>44937986_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clip_id  PatientID    study_id  \\\n",
       "0    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   52426014  52426014_7   \n",
       "1    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   60916943  60916943_4   \n",
       "2    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   52426014  52426014_5   \n",
       "3    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   80306634  80306634_6   \n",
       "4    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   54258868  54258868_4   \n",
       "..                                                 ...        ...         ...   \n",
       "387  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   61398238  61398238_7   \n",
       "388  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   14184938  14184938_3   \n",
       "389  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   37292786  37292786_4   \n",
       "390  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   61308381  61308381_2   \n",
       "391  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...   44937986  44937986_5   \n",
       "\n",
       "     Reader2_A-line  B-line_lbl  Confluent B-line_lbl  Reader2_Consolidation  \\\n",
       "0                 0           0                     0                      0   \n",
       "1                 0           0                     0                      0   \n",
       "2                 0           0                     0                      0   \n",
       "3                 1           0                     0                      0   \n",
       "4                 0           0                     0                      1   \n",
       "..              ...         ...                   ...                    ...   \n",
       "387               0           0                     0                      0   \n",
       "388               0           0                     0                      0   \n",
       "389               0           0                     1                      0   \n",
       "390               1           0                     0                      0   \n",
       "391               0           0                     0                      0   \n",
       "\n",
       "     Reader2_Pleural effusion  Data_idx  Reader2_total-B-line  \n",
       "0                           0         7                     0  \n",
       "1                           0         4                     0  \n",
       "2                           0         5                     0  \n",
       "3                           0         6                     0  \n",
       "4                           0         4                     0  \n",
       "..                        ...       ...                   ...  \n",
       "387                         0         7                     0  \n",
       "388                         0         3                     0  \n",
       "389                         0         4                     1  \n",
       "390                         0         2                     0  \n",
       "391                         0         5                     0  \n",
       "\n",
       "[392 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader1_gt = reader1_gt.rename(columns={\"256_clip_path\": \"clip_id\"})\n",
    "reader2_gt = reader2_gt.rename(columns={\"256_clip_path\": \"clip_id\"})\n",
    "reader2_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼만 선택\n",
    "models_gt_sel = expert_gt[[\n",
    "    \"clip_id\", \"Expert_A-line\", \"Expert_total-B-line\", \n",
    "    \"Expert_Consolidation\", \"Expert_Pleural effusion\"\n",
    "]]\n",
    "\n",
    "reader1_sel = reader1_gt[[\n",
    "    \"clip_id\", \"Reader1_A-line\", \"Reader1_total-B-line\", \n",
    "    \"Reader1_Consolidation\", \"Reader1_Pleural effusion\"\n",
    "]]\n",
    "\n",
    "reader2_sel = reader2_gt[[\n",
    "    \"clip_id\", \"Reader2_A-line\", \"Reader2_total-B-line\", \n",
    "    \"Reader2_Consolidation\", \"Reader2_Pleural effusion\"\n",
    "]]\n",
    "\n",
    "ai_sel = LUV_Net_outputs[[\n",
    "    \"clip_id\", \"AI_A-line\", \"AI_total-B-line\", \n",
    "    \"AI_Consolidation\", \"AI_Pleural effusion\"\n",
    "]]\n",
    "\n",
    "merged_df = models_gt_sel \\\n",
    "    .merge(reader1_sel, on=\"clip_id\", how=\"inner\") \\\n",
    "    .merge(reader2_sel, on=\"clip_id\", how=\"inner\") \\\n",
    "    .merge(ai_sel, on=\"clip_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>Expert_A-line</th>\n",
       "      <th>Expert_total-B-line</th>\n",
       "      <th>Expert_Consolidation</th>\n",
       "      <th>Expert_Pleural effusion</th>\n",
       "      <th>Reader1_A-line</th>\n",
       "      <th>Reader1_total-B-line</th>\n",
       "      <th>Reader1_Consolidation</th>\n",
       "      <th>Reader1_Pleural effusion</th>\n",
       "      <th>Reader2_A-line</th>\n",
       "      <th>Reader2_total-B-line</th>\n",
       "      <th>Reader2_Consolidation</th>\n",
       "      <th>Reader2_Pleural effusion</th>\n",
       "      <th>AI_A-line</th>\n",
       "      <th>AI_total-B-line</th>\n",
       "      <th>AI_Consolidation</th>\n",
       "      <th>AI_Pleural effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>/data2/hoon2/LUS_Dataset/clip_avi_temporally_s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clip_id  Expert_A-line  \\\n",
       "0    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "1    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "2    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "3    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "4    /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "..                                                 ...            ...   \n",
       "387  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "388  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "389  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "390  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "391  /data2/hoon2/LUS_Dataset/clip_avi_temporally_s...            1.0   \n",
       "\n",
       "     Expert_total-B-line  Expert_Consolidation  Expert_Pleural effusion  \\\n",
       "0                    0.0                   0.0                      0.0   \n",
       "1                    0.0                   0.0                      0.0   \n",
       "2                    0.0                   0.0                      0.0   \n",
       "3                    0.0                   0.0                      0.0   \n",
       "4                    0.0                   0.0                      0.0   \n",
       "..                   ...                   ...                      ...   \n",
       "387                  0.0                   1.0                      0.0   \n",
       "388                  0.0                   1.0                      0.0   \n",
       "389                  0.0                   1.0                      0.0   \n",
       "390                  0.0                   1.0                      0.0   \n",
       "391                  0.0                   1.0                      0.0   \n",
       "\n",
       "     Reader1_A-line  Reader1_total-B-line  Reader1_Consolidation  \\\n",
       "0                 1                     0                      0   \n",
       "1                 1                     0                      0   \n",
       "2                 1                     0                      0   \n",
       "3                 1                     0                      0   \n",
       "4                 1                     0                      0   \n",
       "..              ...                   ...                    ...   \n",
       "387               1                     1                      0   \n",
       "388               1                     1                      0   \n",
       "389               1                     1                      0   \n",
       "390               1                     1                      0   \n",
       "391               1                     1                      0   \n",
       "\n",
       "     Reader1_Pleural effusion  Reader2_A-line  Reader2_total-B-line  \\\n",
       "0                           0               1                     0   \n",
       "1                           0               1                     0   \n",
       "2                           0               1                     0   \n",
       "3                           0               1                     0   \n",
       "4                           0               1                     0   \n",
       "..                        ...             ...                   ...   \n",
       "387                         0               0                     1   \n",
       "388                         0               0                     1   \n",
       "389                         0               0                     1   \n",
       "390                         0               0                     1   \n",
       "391                         0               0                     1   \n",
       "\n",
       "     Reader2_Consolidation  Reader2_Pleural effusion  AI_A-line  \\\n",
       "0                        0                         0          1   \n",
       "1                        0                         0          1   \n",
       "2                        0                         0          1   \n",
       "3                        0                         0          1   \n",
       "4                        0                         0          1   \n",
       "..                     ...                       ...        ...   \n",
       "387                      0                         0          0   \n",
       "388                      0                         0          0   \n",
       "389                      0                         0          0   \n",
       "390                      0                         0          0   \n",
       "391                      0                         0          0   \n",
       "\n",
       "     AI_total-B-line  AI_Consolidation  AI_Pleural effusion  \n",
       "0                  0                 0                    0  \n",
       "1                  0                 0                    0  \n",
       "2                  0                 0                    0  \n",
       "3                  0                 0                    0  \n",
       "4                  0                 0                    0  \n",
       "..               ...               ...                  ...  \n",
       "387                1                 0                    0  \n",
       "388                1                 0                    0  \n",
       "389                1                 0                    0  \n",
       "390                1                 0                    0  \n",
       "391                1                 0                    0  \n",
       "\n",
       "[392 rows x 17 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clinician-level Agreement & Experience-based Comparison\n",
    "- **AI가 clinician과 얼마나 일치하는지**: AI vs Reader1, AI vs Reader2\n",
    "\n",
    "- **경험 차이에 따른 판단 비교**: Reader1 vs Expert, Reader2 vs Expert\n",
    "\n",
    "- **두 clinician 간 일관성**: Reader1 vs Reader2\n",
    "\n",
    "- **평가지표**: Agreement Rate, Cohen’s Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"A-line\", \"total-B-line\", \"Consolidation\", \"Pleural effusion\"]\n",
    "\n",
    "comparison_pairs = [\n",
    "    (\"AI\", \"Reader1\"),\n",
    "    (\"AI\", \"Reader2\"),\n",
    "    (\"Reader1\", \"Expert\"),\n",
    "    (\"Reader2\", \"Expert\"),\n",
    "    (\"Reader1\", \"Reader2\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Agreement Rate</th>\n",
       "      <th>Cohen's Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-line</td>\n",
       "      <td>AI vs Reader1</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-line</td>\n",
       "      <td>AI vs Reader2</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-line</td>\n",
       "      <td>Reader1 vs Expert</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-line</td>\n",
       "      <td>Reader2 vs Expert</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-line</td>\n",
       "      <td>Reader1 vs Reader2</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total-B-line</td>\n",
       "      <td>AI vs Reader1</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total-B-line</td>\n",
       "      <td>AI vs Reader2</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total-B-line</td>\n",
       "      <td>Reader1 vs Expert</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total-B-line</td>\n",
       "      <td>Reader2 vs Expert</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total-B-line</td>\n",
       "      <td>Reader1 vs Reader2</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>AI vs Reader1</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>AI vs Reader2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>Reader1 vs Expert</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>Reader2 vs Expert</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>Reader1 vs Reader2</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pleural effusion</td>\n",
       "      <td>AI vs Reader1</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pleural effusion</td>\n",
       "      <td>AI vs Reader2</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pleural effusion</td>\n",
       "      <td>Reader1 vs Expert</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pleural effusion</td>\n",
       "      <td>Reader2 vs Expert</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pleural effusion</td>\n",
       "      <td>Reader1 vs Reader2</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Label          Comparison  Agreement Rate  Cohen's Kappa\n",
       "0             A-line       AI vs Reader1           0.656          0.279\n",
       "1             A-line       AI vs Reader2           0.668          0.387\n",
       "2             A-line   Reader1 vs Expert           0.821          0.574\n",
       "3             A-line   Reader2 vs Expert           0.452          0.155\n",
       "4             A-line  Reader1 vs Reader2           0.579          0.258\n",
       "5       total-B-line       AI vs Reader1           0.758          0.524\n",
       "6       total-B-line       AI vs Reader2           0.658          0.348\n",
       "7       total-B-line   Reader1 vs Expert           0.732          0.449\n",
       "8       total-B-line   Reader2 vs Expert           0.730          0.415\n",
       "9       total-B-line  Reader1 vs Reader2           0.696          0.321\n",
       "10     Consolidation       AI vs Reader1           0.776          0.344\n",
       "11     Consolidation       AI vs Reader2           0.875          0.413\n",
       "12     Consolidation   Reader1 vs Expert           0.745          0.355\n",
       "13     Consolidation   Reader2 vs Expert           0.819          0.416\n",
       "14     Consolidation  Reader1 vs Reader2           0.737          0.229\n",
       "15  Pleural effusion       AI vs Reader1           0.969          0.837\n",
       "16  Pleural effusion       AI vs Reader2           0.916          0.517\n",
       "17  Pleural effusion   Reader1 vs Expert           0.954          0.702\n",
       "18  Pleural effusion   Reader2 vs Expert           0.977          0.835\n",
       "19  Pleural effusion  Reader1 vs Reader2           0.931          0.534"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "agreement_results = []\n",
    "kappa_results = []\n",
    "\n",
    "for label in labels:\n",
    "    for a, b in comparison_pairs:\n",
    "        col_a = f\"{a}_{label}\"\n",
    "        col_b = f\"{b}_{label}\"\n",
    "        y_true = merged_df[col_a]\n",
    "        y_pred = merged_df[col_b]\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        agreement_results.append({\n",
    "            \"Label\": label,\n",
    "            \"Comparison\": f\"{a} vs {b}\",\n",
    "            \"Agreement Rate\": round(acc, 3),\n",
    "            \"Cohen's Kappa\": round(kappa, 3)\n",
    "        })\n",
    "agreement_df = pd.DataFrame(agreement_results)\n",
    "agreement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consensus Accuracy\n",
    "- **Reader1 + Reader2의 majority voting을 기준으로**\n",
    "\n",
    "    - AI와 Consensus label 간 정확도\n",
    "\n",
    "    - Expert와 Consensus label 간 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consensus accuracy\n",
    "consensus_results = []\n",
    "for label in labels:\n",
    "    reader1 = merged_df[f\"Reader1_{label}\"]\n",
    "    reader2 = merged_df[f\"Reader2_{label}\"]\n",
    "    consensus = ((reader1 + reader2) >= 1).astype(int)\n",
    "    expert = merged_df[f\"Expert_{label}\"]\n",
    "    ai = merged_df[f\"AI_{label}\"]\n",
    "    acc_ai_vs_consensus = accuracy_score(consensus, ai)\n",
    "    acc_expert_vs_consensus = accuracy_score(consensus, expert)\n",
    "    consensus_results.append({\n",
    "        \"Label\": label,\n",
    "        \"AI vs Consensus Accuracy\": round(acc_ai_vs_consensus, 3),\n",
    "        \"Expert vs Consensus Accuracy\": round(acc_expert_vs_consensus, 3)\n",
    "    })\n",
    "consensus_df = pd.DataFrame(consensus_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35d898d7f71d15b3f246fb4980c4f70ef429f643dfeb843caf2da7fdda6d8d40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
